{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4c351481",
      "metadata": {
        "id": "4c351481"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dusdnKR/SWCON425/blob/main/hw04_for_students/hw04_for_students.ipynb?hl=ko\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7439f23a",
      "metadata": {
        "id": "7439f23a"
      },
      "source": [
        "# Homework 4: Training Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bab5cefb",
      "metadata": {
        "id": "bab5cefb"
      },
      "source": [
        "### Due Date: Monday 12/22, 23:59\n",
        "\n",
        "Homework 4 is out, it is notebook form. You need to fill in the answers in the cells and produce graphs. Everything needed for the assignment is explained in the notebook.\n",
        "\n",
        "**How to submit**\n",
        "\n",
        "You need to send the `.ipynb` file with your answers plus an `.html` file, which will serve as a backup for us in case the `.ipynb` file cannot be opened on my or the TA's computer.\n",
        "\n",
        "The homework solution should be uploaded on e-campus. You can submit it as often as you like before the deadline.\n",
        "\n",
        "**Important**\n",
        "- Please make sure that you provide an answer in each cell and place that contains the **[ your answer ]** tags.\n",
        "- The places that require your code answer are marked with \"`### YOUR CODE`\" comments.\n",
        "- Note that you may use 1 or more line of code for replacing each \"`### YOUR CODE`\" comment."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2aba87a",
      "metadata": {
        "id": "b2aba87a"
      },
      "source": [
        "## Part 1: Transformers Review [30 points]\n",
        "\n",
        "In this part, you will implement key components of the GPT model architecture based on what you learned in previous lectures.  \n",
        "This will help you understand how transformers work at a fundamental level."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "fb2d06f1",
      "metadata": {
        "id": "fb2d06f1",
        "outputId": "93b3d318-0f08-4c62-9769-cb314f14fef8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "matplotlib version: 3.10.0\n",
            "numpy version: 2.0.2\n",
            "tiktoken version: 0.12.0\n",
            "torch version: 2.9.0+cpu\n",
            "tensorflow version: 2.19.0\n"
          ]
        }
      ],
      "source": [
        "from importlib.metadata import version\n",
        "\n",
        "pkgs = [\"matplotlib\",\n",
        "        \"numpy\",\n",
        "        \"tiktoken\",\n",
        "        \"torch\",\n",
        "        \"tensorflow\"\n",
        "       ]\n",
        "for p in pkgs:\n",
        "    print(f\"{p} version: {version(p)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1eb49d73",
      "metadata": {
        "id": "1eb49d73"
      },
      "source": [
        "### Question 1-1) `GPTDatasetV1` [5 points]\n",
        "\n",
        "Implement the dataset class that creates input-target pairs for GPT training.\n",
        "\n",
        "**HINT**\n",
        "- `input_chunk` contains tokens from `i` to `i + max_length`.\n",
        "- `target_chunk` returns the tokens immediately following `input_chunk` (shifted by one position)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "23878359",
      "metadata": {
        "id": "23878359"
      },
      "outputs": [],
      "source": [
        "import tiktoken\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class GPTDatasetV1(Dataset):\n",
        "    def __init__(self, txt, tokenizer, max_length, stride):\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "\n",
        "        # Tokenize the entire text\n",
        "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
        "\n",
        "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
        "        for i in range(0, len(token_ids) - max_length, stride):\n",
        "            input_chunk = token_ids[i:i + max_length]\n",
        "            target_chunk = token_ids[i + 1:i + max_length + 1]\n",
        "            self.input_ids.append(torch.tensor(input_chunk))\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx]\n",
        "\n",
        "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
        "                         stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
        "    # Initialize the tokenizer\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "    # Create dataset\n",
        "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "\n",
        "    # Create dataloader\n",
        "    dataloader = DataLoader(\n",
        "        dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n",
        "\n",
        "    return dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3366ab0",
      "metadata": {
        "id": "b3366ab0"
      },
      "source": [
        "### Question 1-2) `MultiHeadAttention` [5 points]\n",
        "\n",
        "Implement the multi-head attention mechanism which is the core component of transformers.\n",
        "\n",
        "**HINT**\n",
        "- `head_dim` is the value obtained by dividing `d_out` by `num_heads`.\n",
        "- `keys`, `queries`, and `values` are the outputs obtained by passing the input (`x`) through the `W_key`, `W_query`, and `W_value` layers, respectively.\n",
        "- In the initial shape `(b, num_tokens, d_out)` of `keys`, `queries`, and `values`, the `d_out` dimension must be split into `num_heads` and `head_dim` for per-head computation.\n",
        "- To perform computations across `num_tokens` and `head_dim`, the order of `num_heads` and `num_tokens` is swapped.\n",
        "- `attn_scores` are computed by taking the matrix multiplication (`@`) of `queries` and the transpose of `keys`.\n",
        "- `attn_weights` are obtained by applying softmax to `attn_scores` after scaling them by the square root of the dimensionality of the `keys`, `queries`, and `values`.\n",
        "- Before computing `context_vec`, dropout is applied.\n",
        "- `context_vec` is computed by taking the matrix multiplication (`@`) of `attn_weights` and `values`.\n",
        "- The final output shape must be the same as the input shape `(b, num_tokens, d_out)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2b1354be",
      "metadata": {
        "id": "2b1354be"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert d_out % num_heads == 0, \"d_out must be divisible by n_heads\"\n",
        "\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = d_out // num_heads\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer(\"mask\", torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        keys = self.W_key(x)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
        "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
        "        attn_scores = queries @ keys.transpose(2, 3)\n",
        "\n",
        "        # Original mask truncated to the number of tokens and converted to boolean\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "        # Use the mask to fill attention scores\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
        "        context_vec = context_vec.reshape(b, num_tokens, self.d_out)\n",
        "        context_vec = self.out_proj(context_vec)  # optional projection\n",
        "\n",
        "        return context_vec"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8f6098f",
      "metadata": {
        "id": "e8f6098f"
      },
      "source": [
        "### Question 1-3) `LayerNorm` [5 points]\n",
        "\n",
        "Implement Layer Normalization which stabilizes training by normalizing inputs.\n",
        "\n",
        "**HINT**\n",
        "- `norm_x` is the result of normalizing `x` by subtracting the mean and dividing by the standard deviation.\n",
        "- To prevent division by zero, an `eps` value is added to the denominator.\n",
        "- The final returned value is obtained by multiplying `norm_x` by `scale` and then adding `shift`, where `scale` and `shift` are learnable parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d5d166b6",
      "metadata": {
        "id": "d5d166b6"
      },
      "outputs": [],
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        return self.scale * norm_x + self.shift"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8828d4cf",
      "metadata": {
        "id": "8828d4cf"
      },
      "source": [
        "### `GELU`\n",
        "\n",
        "The GELU activation function is provided for you (no implementation needed)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e34474a7",
      "metadata": {
        "id": "e34474a7"
      },
      "outputs": [],
      "source": [
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e70fe80e",
      "metadata": {
        "id": "e70fe80e"
      },
      "source": [
        "### Question 1-4) `FeedForward` [5 points]\n",
        "\n",
        "Implement the Feed-Forward network that processes each position independently.\n",
        "\n",
        "**HINT**\n",
        "- `FeedForward` uses linear layers to expand the dimensionality by a factor of 4, applies GELU, and then projects the dimension back to the original size.\n",
        "- The input dimension is stored in `cfg[\"emb_dim\"]`.\n",
        "- Layers inside `nn.Sequential()` are separated by commas (`,`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "b2f71955",
      "metadata": {
        "id": "b2f71955"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26dd415f",
      "metadata": {
        "id": "26dd415f"
      },
      "source": [
        "### Question 1-5) `TransformerBlock` [5 points]\n",
        "\n",
        "Implement a complete Transformer block with attention and feed-forward layers.\n",
        "\n",
        "**HINT**\n",
        "- The order of operations in `TransformerBlock` is as follows:  \n",
        "`LayerNorm(1)` → `Masked Multi-head Attention` → `Dropout` + `Shortcut Connection` →  \n",
        "`LayerNorm(2)` → `FeedForward` → `Dropout` + `Shortcut Connection`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ee522d6b",
      "metadata": {
        "id": "ee522d6b"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            dropout=cfg[\"drop_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"])\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Shortcut connection for attention block\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut\n",
        "\n",
        "        # Shortcut connection for feed-forward block\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_shortcut(x)\n",
        "        x = x + shortcut\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64b604ef",
      "metadata": {
        "id": "64b604ef"
      },
      "source": [
        "### Question 1-6) `GPTModel` [5 points]\n",
        "\n",
        "Complete the GPT model by assembling all components together.\n",
        "\n",
        "**HINT**\n",
        "- The input `x` is the sum of the token embeddings and the positional embeddings.\n",
        "- The order of operations in `GPTModel` is as follows:  \n",
        "`Token Embedding` + `Position Embedding` → `Dropout` → `TransformerBlock` * 12 → `LayerNorm` → `Linear`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "1d24d22c",
      "metadata": {
        "id": "1d24d22c"
      },
      "outputs": [],
      "source": [
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d321f14",
      "metadata": {
        "id": "6d321f14"
      },
      "source": [
        "### Testing Your Implementation\n",
        "\n",
        "If all of the above classes are implemented correctly, you should see the output of the code below.  \n",
        "This generates text using an untrained model (<b>so the output will be random</b>)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "25192b7d",
      "metadata": {
        "id": "25192b7d",
        "outputId": "fa8e5e34-2687-4f93-8de8-7b6530cb247e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "                      IN\n",
            "==================================================\n",
            "\n",
            "Input text: Hello, I am\n",
            "Encoded input text: [15496, 11, 314, 716]\n",
            "encoded_tensor.shape: torch.Size([1, 4])\n",
            "\n",
            "\n",
            "==================================================\n",
            "                      OUT\n",
            "==================================================\n",
            "\n",
            "Output: tensor([[15496,    11,   314,   716, 27018, 24086, 47843, 30961, 42348,  7267,\n",
            "         49706, 43231, 47062, 34657]])\n",
            "Output length: 14\n",
            "Output text: Hello, I am Featureiman Byeswickattribute argue logger Normandy Compton analogous\n"
          ]
        }
      ],
      "source": [
        "def generate_text_simple(model, idx, max_new_tokens, context_size):\n",
        "    for _ in range(max_new_tokens):\n",
        "\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
        "\n",
        "        idx = torch.cat((idx, idx_next), dim=1)\n",
        "\n",
        "    return idx\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    GPT_CONFIG_124M = {\n",
        "        \"vocab_size\": 50257,     # Vocabulary size\n",
        "        \"context_length\": 1024,  # Context length\n",
        "        \"emb_dim\": 768,          # Embedding dimension\n",
        "        \"n_heads\": 12,           # Number of attention heads\n",
        "        \"n_layers\": 12,          # Number of layers\n",
        "        \"drop_rate\": 0.1,        # Dropout rate\n",
        "        \"qkv_bias\": False        # Query-Key-Value bias\n",
        "    }\n",
        "\n",
        "    torch.manual_seed(123)\n",
        "    model = GPTModel(GPT_CONFIG_124M)\n",
        "    model.eval()  # disable dropout\n",
        "\n",
        "    start_context = \"Hello, I am\"\n",
        "\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "    encoded = tokenizer.encode(start_context)\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
        "\n",
        "    print(f\"\\n{50*'='}\\n{22*' '}IN\\n{50*'='}\")\n",
        "    print(\"\\nInput text:\", start_context)\n",
        "    print(\"Encoded input text:\", encoded)\n",
        "    print(\"encoded_tensor.shape:\", encoded_tensor.shape)\n",
        "\n",
        "    out = generate_text_simple(\n",
        "        model=model,\n",
        "        idx=encoded_tensor,\n",
        "        max_new_tokens=10,\n",
        "        context_size=GPT_CONFIG_124M[\"context_length\"]\n",
        "    )\n",
        "    decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
        "\n",
        "    print(f\"\\n\\n{50*'='}\\n{22*' '}OUT\\n{50*'='}\")\n",
        "    print(\"\\nOutput:\", out)\n",
        "    print(\"Output length:\", len(out[0]))\n",
        "    print(\"Output text:\", decoded_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83557fa4",
      "metadata": {
        "id": "83557fa4"
      },
      "source": [
        "The above result shows the output of an untrained LLM model. In the next part, you will train this model!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51f7f22d",
      "metadata": {
        "id": "51f7f22d"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 2: Model Training [40 points]\n",
        "\n",
        "In this part, you will experience the complete training process of a language model.  \n",
        "You will prepare training data, implement the training loop, and monitor the model's learning progress."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "625f0df4",
      "metadata": {
        "id": "625f0df4"
      },
      "source": [
        "### Setup Training Configuration\n",
        "\n",
        "We'll use a smaller context length (256 instead of 1024) to reduce computational requirements while still demonstrating the training process effectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "bf63e620",
      "metadata": {
        "id": "bf63e620"
      },
      "outputs": [],
      "source": [
        "GPT_CONFIG_124M = {\n",
        "    \"vocab_size\": 50257,     # Vocabulary size\n",
        "    \"context_length\": 256,   # Context length\n",
        "    \"emb_dim\": 768,          # Embedding dimension\n",
        "    \"n_heads\": 12,           # Number of attention heads\n",
        "    \"n_layers\": 12,          # Number of layers\n",
        "    \"drop_rate\": 0.1,        # Dropout rate\n",
        "    \"qkv_bias\": False        # Query-Key-Value bias\n",
        "}\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.eval(); # disable dropout evaluation mode"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffcba06a",
      "metadata": {
        "id": "ffcba06a"
      },
      "source": [
        "### Prepare Training Data\n",
        "\n",
        "Download and prepare the training dataset. We'll use the short story \"`The Verdict`\" for training.\n",
        "\n",
        "**Note**: This is a very small training dataset for educational purposes. In practice, LLMs are trained on billions of tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "6296c384",
      "metadata": {
        "id": "6296c384",
        "outputId": "43117d21-4833-4a13-8e41-c3f798b759ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 100 characters:\n",
            "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no g\n",
            "\n",
            "Last 100 characters:\n",
            " it for me! The Strouds stand alone, and happen once--but there's no exterminating our kind of art.\"\n",
            "\n",
            "Total characters: 20479\n",
            "Total tokens: 5145\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "file_path = \"the-verdict.txt\"\n",
        "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
        "\n",
        "if not os.path.exists(file_path):\n",
        "    response = requests.get(url, timeout=30)\n",
        "    response.raise_for_status()\n",
        "    text_data = response.text\n",
        "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
        "        file.write(text_data)\n",
        "else:\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        text_data = file.read()\n",
        "\n",
        "# Verify the data\n",
        "print(\"First 100 characters:\")\n",
        "print(text_data[:100])\n",
        "print(\"\\nLast 100 characters:\")\n",
        "print(text_data[-100:])\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "total_characters = len(text_data)\n",
        "total_tokens = len(tokenizer.encode(text_data))\n",
        "\n",
        "print(f\"\\nTotal characters: {total_characters}\")\n",
        "print(f\"Total tokens: {total_tokens}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4560764f",
      "metadata": {
        "id": "4560764f"
      },
      "source": [
        "### Question 2-1) Create Data Loaders [5 points]\n",
        "\n",
        "Split the data into training and validation sets, then create data loaders.\n",
        "\n",
        "**HINT**\n",
        "- Use 90% of data for training and 10% for validation.\n",
        "- `train_data` and `val_data` are split based on `split_idx`. If the split is done correctly, their lengths will be 18,431 and 2,048, respectively.\n",
        "- `train_loader` is identical to `val_loader`, but the `drop_last` and `shuffle` settings must be set to `True`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "a67c2e76",
      "metadata": {
        "id": "a67c2e76",
        "outputId": "357ac639-1465-4399-8c96-9d858b6924fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data length: 18431\n",
            "Validation data length: 2048\n",
            "\n",
            "Training data loader:\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n",
            "\n",
            "Validation data loader:\n",
            "torch.Size([2, 256]) torch.Size([2, 256])\n"
          ]
        }
      ],
      "source": [
        "# Split data into training and validation sets\n",
        "train_ratio = 0.9\n",
        "split_idx = int(train_ratio * len(text_data))\n",
        "train_data = text_data[:split_idx]\n",
        "val_data = text_data[split_idx:]\n",
        "\n",
        "print(f\"Training data length: {len(train_data)}\")\n",
        "print(f\"Validation data length: {len(val_data)}\")\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader = create_dataloader_v1(\n",
        "    train_data,\n",
        "    batch_size=2,\n",
        "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "    drop_last=True,\n",
        "    shuffle=True,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "val_loader = create_dataloader_v1(\n",
        "    val_data,\n",
        "    batch_size=2,\n",
        "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "    drop_last=False,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "# Verify data loaders\n",
        "print(\"\\nTraining data loader:\")\n",
        "for x, y in train_loader:\n",
        "    print(x.shape, y.shape)\n",
        "\n",
        "print(\"\\nValidation data loader:\")\n",
        "for x, y in val_loader:\n",
        "    print(x.shape, y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "187388cf",
      "metadata": {
        "id": "187388cf"
      },
      "source": [
        "### Implement Loss Calculation\n",
        "\n",
        "Implement functions to calculate the cross-entropy loss for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "6041c1b8",
      "metadata": {
        "id": "6041c1b8"
      },
      "outputs": [],
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)\n",
        "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
        "    return loss\n",
        "\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b77174bd",
      "metadata": {
        "id": "b77174bd"
      },
      "source": [
        "### Question 2-2) Cross Entropy [5 points]\n",
        "\n",
        "In `calc_loss_batch`, <b>what reference values</b> are used to calculate the loss?  \n",
        "Explain <b>the loss calculation method</b> and <b>the final objective</b> in particular."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bd6d636",
      "metadata": {
        "id": "2bd6d636"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "calc_loss_batch 함수에서는 loss를 계산하기 위해 모델의 예측값인 logits와\n",
        "데이터셋의 실제 정답인 target_batch를 참조한다.\n",
        "\n",
        "input_batch를 모델에 넣어 logit을 얻고\n",
        "3차원인 logits를 2차원으로 flatten하고 target_batch도 1차원으로 flatten한다.\n",
        "변환한 logits와 target_batch를 cross entropy 함수에 넣으면\n",
        "cross entropy 함수는 softmax를 적용해서 예측 확률을 구한다.\n",
        "\n",
        "최종 목적은 예측 확률 분포와 실제 정답 분포 사이 오차를 수치화하고\n",
        "이를 최소화하도록 가중치를 업데이트해 예측 성능을 높이는 것이다.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba953ddb",
      "metadata": {
        "id": "ba953ddb"
      },
      "source": [
        "### Setup Device and Initial Loss\n",
        "\n",
        "Check if GPU is available and calculate initial loss before training. It will take some time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "1b7dfa7e",
      "metadata": {
        "id": "1b7dfa7e",
        "outputId": "92afb5a7-1e26-44ef-d2ac-b5a6bdff61a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device.\n",
            "Training loss: 10.988\n",
            "Validation loss: 10.981\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "elif torch.backends.mps.is_available():\n",
        "    major, minor = map(int, torch.__version__.split(\".\")[:2])\n",
        "    if (major, minor) >= (2, 9):\n",
        "        device = torch.device(\"mps\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(f\"Using {device} device.\")\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "with torch.no_grad():\n",
        "    train_loss = calc_loss_loader(train_loader, model, device)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device)\n",
        "\n",
        "print(f\"Training loss: {train_loss:.3f}\")\n",
        "print(f\"Validation loss: {val_loss:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94fd292d",
      "metadata": {
        "id": "94fd292d"
      },
      "source": [
        "### Implement Training Loop\n",
        "\n",
        "Implement the main training loop that will train your model.\n",
        "\n",
        "- In each training step: `zero gradients` → `forward pass` → `calculate loss` → `backward pass` → `update weights`\n",
        "- Track tokens seen and global step.\n",
        "- Periodically evaluate on both training and validation sets.\n",
        "- Generate sample text after each epoch to see progress."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "91e7edd4",
      "metadata": {
        "id": "91e7edd4"
      },
      "outputs": [],
      "source": [
        "def text_to_token_ids(text, tokenizer):\n",
        "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
        "    return encoded_tensor\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "    flat = token_ids.squeeze(0)\n",
        "    return tokenizer.decode(flat.tolist())\n",
        "\n",
        "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                       eval_freq, eval_iter, start_context, tokenizer):\n",
        "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "    tokens_seen, global_step = 0, -1\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            tokens_seen += input_batch.numel()\n",
        "            global_step += 1\n",
        "\n",
        "            # Evaluate at specified frequency\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "                print(f\"Epoch {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Generate sample text after each epoch\n",
        "        generate_and_print_sample(\n",
        "            model, tokenizer, device, start_context\n",
        "        )\n",
        "\n",
        "    return train_losses, val_losses, track_tokens_seen\n",
        "\n",
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss\n",
        "\n",
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "    model.eval()\n",
        "    context_size = model.pos_emb.weight.shape[0]\n",
        "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "    with torch.no_grad():\n",
        "        token_ids = generate_text_simple(\n",
        "            model=model, idx=encoded,\n",
        "            max_new_tokens=50, context_size=context_size\n",
        "        )\n",
        "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    print(decoded_text.replace(\"\\n\", \" \"))\n",
        "    model.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19d95628",
      "metadata": {
        "id": "19d95628"
      },
      "source": [
        "### Train the Model\n",
        "\n",
        "Now execute the training! This will take a few minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "406f4a5e",
      "metadata": {
        "id": "406f4a5e",
        "outputId": "54001b76-deec-4c7b-f18c-3e13556512dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 (Step 000000): Train loss 9.781, Val loss 9.933\n",
            "Epoch 1 (Step 000005): Train loss 8.111, Val loss 8.339\n",
            "Every effort moves you,,,,,,,,,,,,.                                     \n",
            "Epoch 2 (Step 000010): Train loss 6.661, Val loss 7.048\n",
            "Epoch 2 (Step 000015): Train loss 5.961, Val loss 6.616\n",
            "Every effort moves you, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and,, and, and,\n",
            "Epoch 3 (Step 000020): Train loss 5.723, Val loss 6.598\n",
            "Epoch 3 (Step 000025): Train loss 5.204, Val loss 6.351\n",
            "Every effort moves you, and I had been.                                            \n",
            "Epoch 4 (Step 000030): Train loss 4.420, Val loss 6.279\n",
            "Epoch 4 (Step 000035): Train loss 4.071, Val loss 6.226\n",
            "Every effort moves you know the                          \"I he had the donkey and I had the and I had the donkey and down the room, I had\n",
            "Epoch 5 (Step 000040): Train loss 3.733, Val loss 6.160\n",
            "Every effort moves you know it was not that the picture--I had the fact by the last I had been--his, and in the            \"Oh, and he said, and down the room, and in\n",
            "Epoch 6 (Step 000045): Train loss 2.852, Val loss 6.180\n",
            "Epoch 6 (Step 000050): Train loss 2.429, Val loss 6.140\n",
            "Every effort moves you know,\" was one of the picture. The--I had a little of a little: \"Yes, and in fact, and in the picture was, and I had been at my elbow and as his pictures, and down the room, I had\n",
            "Epoch 7 (Step 000055): Train loss 2.106, Val loss 6.134\n",
            "Epoch 7 (Step 000060): Train loss 1.883, Val loss 6.233\n",
            "Every effort moves you know,\" was one of the picture for nothing--I told Mrs.  \"I was no--as! The women had been, in the moment--as Jack himself, as once one had been the donkey, and were, and in his\n",
            "Epoch 8 (Step 000065): Train loss 1.321, Val loss 6.239\n",
            "Epoch 8 (Step 000070): Train loss 0.986, Val loss 6.243\n",
            "Every effort moves you know,\" was one of the axioms he had been the tips of a self-confident moustache, I felt to see a smile behind his close grayish beard--as if he had the donkey. \"strongest,\" as his\n",
            "Epoch 9 (Step 000075): Train loss 0.717, Val loss 6.293\n",
            "Epoch 9 (Step 000080): Train loss 0.542, Val loss 6.393\n",
            "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back the window-curtains, I had the donkey. \"There were days when I\n",
            "Epoch 10 (Step 000085): Train loss 0.391, Val loss 6.452\n",
            "Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed luncheon-table, when, on a later day, I had again run over from Monte Carlo; and Mrs. Gis\n",
            "\n",
            "Training completed in 20.21 minutes.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 10\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"\\nTraining completed in {execution_time_minutes:.2f} minutes.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77d5715a",
      "metadata": {
        "id": "77d5715a"
      },
      "source": [
        "### Question 2-3) Training Results [20 points]\n",
        "Please copy the output of the block above.\n",
        "\n",
        "**HINT**\n",
        "- The results include `Train loss`, `Val loss`, example generation results, and final training time for each epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb7bfc38",
      "metadata": {
        "id": "bb7bfc38"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Epoch 1 (Step 000000): Train loss 9.781, Val loss 9.933\n",
        "Epoch 1 (Step 000005): Train loss 8.111, Val loss 8.339\n",
        "Every effort moves you,,,,,,,,,,,,.\n",
        "Epoch 2 (Step 000010): Train loss 6.661, Val loss 7.048\n",
        "Epoch 2 (Step 000015): Train loss 5.961, Val loss 6.616\n",
        "Every effort moves you, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and, and,, and, and,\n",
        "Epoch 3 (Step 000020): Train loss 5.723, Val loss 6.598\n",
        "Epoch 3 (Step 000025): Train loss 5.204, Val loss 6.351\n",
        "Every effort moves you, and I had been.\n",
        "Epoch 4 (Step 000030): Train loss 4.420, Val loss 6.279\n",
        "Epoch 4 (Step 000035): Train loss 4.071, Val loss 6.226\n",
        "Every effort moves you know the                          \"I he had the donkey and I had the and I had the donkey and down the room, I had\n",
        "Epoch 5 (Step 000040): Train loss 3.733, Val loss 6.160\n",
        "Every effort moves you know it was not that the picture--I had the fact by the last I had been--his, and in the            \"Oh, and he said, and down the room, and in\n",
        "Epoch 6 (Step 000045): Train loss 2.852, Val loss 6.180\n",
        "Epoch 6 (Step 000050): Train loss 2.429, Val loss 6.140\n",
        "Every effort moves you know,\" was one of the picture. The--I had a little of a little: \"Yes, and in fact, and in the picture was, and I had been at my elbow and as his pictures, and down the room, I had\n",
        "Epoch 7 (Step 000055): Train loss 2.106, Val loss 6.134\n",
        "Epoch 7 (Step 000060): Train loss 1.883, Val loss 6.233\n",
        "Every effort moves you know,\" was one of the picture for nothing--I told Mrs.  \"I was no--as! The women had been, in the moment--as Jack himself, as once one had been the donkey, and were, and in his\n",
        "Epoch 8 (Step 000065): Train loss 1.321, Val loss 6.239\n",
        "Epoch 8 (Step 000070): Train loss 0.986, Val loss 6.243\n",
        "Every effort moves you know,\" was one of the axioms he had been the tips of a self-confident moustache, I felt to see a smile behind his close grayish beard--as if he had the donkey. \"strongest,\" as his\n",
        "Epoch 9 (Step 000075): Train loss 0.717, Val loss 6.293\n",
        "Epoch 9 (Step 000080): Train loss 0.542, Val loss 6.393\n",
        "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back the window-curtains, I had the donkey. \"There were days when I\n",
        "Epoch 10 (Step 000085): Train loss 0.391, Val loss 6.452\n",
        "Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed luncheon-table, when, on a later day, I had again run over from Monte Carlo; and Mrs. Gis\n",
        "\n",
        "Training completed in 20.21 minutes.\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8a472daa",
      "metadata": {
        "id": "8a472daa"
      },
      "source": [
        "### Question 2-4) Results Analysis [5 points]\n",
        "\n",
        "What is the writing style of the generated example sentence? What might be the reason for it?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61fd8f70",
      "metadata": {
        "id": "61fd8f70"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "generated example sentence:\n",
        "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"\n",
        "He laughed again, and threw back his head to the donkey again. I saw that, and down the room, when I\n",
        "\n",
        "generated된 문장은 대화의 형태로, 단순한 정보 전달이 아닌 등장 인물의 행동과 감정이 묘사되는, 전형적인 소설 문체를 띤다.\n",
        "이는 학습 데이터가 소설이라 그러한 것으로 보인다.\n",
        "그리고 학습 과정에서 train loss는 하락한 반면 val loss는 하락하다가 약간의 상승을 보인다.\n",
        "이는 해당 generated example sentence를 구글에 검색해보면 뜨는\n",
        "'the-verdict' 소설을 위주로 학습하여 과적합 경향을 보이는 것으로 확인된다.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38cc78be",
      "metadata": {
        "id": "38cc78be"
      },
      "source": [
        "### Question 2-5) Visualize Training Progress [5 points]\n",
        "\n",
        "Plot the training and validation losses to see how your model learned over time.\n",
        "\n",
        "**HINT**\n",
        "- Draw a graph using `plot()`.\n",
        "- In the legend, make `train_losses` and `val_losses` have the labels \"Training loss\" and \"Validation loss\".\n",
        "- You are free to choose any other settings as you like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "6257807f",
      "metadata": {
        "id": "6257807f",
        "outputId": "17af53dd-91b6-4d8c-dcd3-7a7a75919f23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxYAAAGGCAYAAADmRxfNAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAbw1JREFUeJzt3Xd4FFXfxvHv7qb3QiopBIhA6F2IHR7AggIi6ouKFQsoPtgL2MX+KBZUVLBjA0UFFZAmUkJvIXQIkAKkJ6TuvH9sWBIJCKRsEu7Pde2V3Zmzs7/FMczNOWeOyTAMAxERERERkWowO7oAERERERFp+BQsRERERESk2hQsRERERESk2hQsRERERESk2hQsRERERESk2hQsRERERESk2hQsRERERESk2hQsRERERESk2hQsRERERESk2hQsRESkSrt378ZkMrF27VpHlyIiIg2AgoWISCNmMplO+nj66acdXaKIiDQSTo4uQEREak9KSor9+TfffMP48eNJSkqyb/Py8nJEWSIi0gipx0JEpBELDQ21P3x9fTGZTPbXwcHBvPHGG0RERODq6kqnTp347bffTnissrIybr31Vlq3bs3evXsB+Omnn+jSpQtubm40b96cZ555htLSUvt7TCYTH330EYMHD8bDw4PY2Fhmzpxp35+Zmcnw4cMJCgrC3d2d2NhYpkyZcsIavv/+e9q3b4+7uzuBgYH07duX/Px8+/6PPvqINm3a4ObmRuvWrXnvvfcqvT85OZlhw4bh5+dHQEAAV111Fbt377bvv/nmmxk0aBCvvfYaYWFhBAYGMmrUKEpKSk75z1xE5GylYCEicpZ66623eP3113nttddYv349/fv358orr2Tbtm3HtS0qKuKaa65h7dq1LF68mKioKBYvXsxNN93EmDFj2Lx5Mx988AFTp07lhRdeqPTeZ555hmHDhrF+/Xouu+wyhg8fTkZGBgDjxo1j8+bNzJ49m8TERCZNmkSTJk2qrDclJYXrr7+eW2+9lcTERBYsWMCQIUMwDAOAL7/8kvHjx/PCCy+QmJjIiy++yLhx4/j0008BKCkpoX///nh7e7N48WKWLFmCl5cXAwYMoLi42P458+fPZ8eOHcyfP59PP/2UqVOnMnXq1Jr4IxcRadwMERE5K0yZMsXw9fW1vw4PDzdeeOGFSm26d+9u3HPPPYZhGMauXbsMwFi8eLHRp08f47zzzjOysrLsbfv06WO8+OKLld7/+eefG2FhYfbXgPHkk0/aX+fl5RmAMXv2bMMwDGPgwIHGLbfcckr1r1q1ygCM3bt3V7m/RYsWxldffVVp23PPPWf06tXLXlurVq0Mq9Vq319UVGS4u7sbv//+u2EYhjFixAgjOjraKC0ttbe55pprjGuvvfaUahQROZtpjoWIyFkoJyeHAwcOEB8fX2l7fHw869atq7Tt+uuvJyIigj///BN3d3f79nXr1rFkyZJKPRRlZWUUFhZSUFCAh4cHAB06dLDv9/T0xMfHh/T0dADuvvturr76alavXk2/fv0YNGgQvXv3rrLmjh070qdPH9q3b0///v3p168fQ4cOxd/fn/z8fHbs2MFtt93GHXfcYX9PaWkpvr6+9nq3b9+Ot7d3peMWFhayY8cO++u2bdtisVjsr8PCwtiwYcNJ/jRFRAQ0eVtERP7FZZddxhdffMHSpUu55JJL7Nvz8vJ45plnGDJkyHHvcXNzsz93dnautM9kMmG1WgG49NJL2bNnD7NmzWLOnDn06dOHUaNG8dprrx13TIvFwpw5c/j777/5448/ePvtt3niiSdYvny5PcRMnjyZnj17Hve+o/V27dqVL7/88rhjBwUFnVK9IiJyYgoWIiJnIR8fH8LDw1myZAkXXnihffuSJUvo0aNHpbZ333037dq148orr+TXX3+1t+/SpQtJSUm0bNmyWrUEBQUxYsQIRowYwfnnn89DDz1UZbAA20V+fHw88fHxjB8/nujoaGbMmMHYsWMJDw9n586dDB8+vMr3dunShW+++Ybg4GB8fHyqVbOIiBxPwUJE5Cz10EMP8dRTT9GiRQs6derElClTWLt2bZX/on/vvfdSVlbGFVdcwezZsznvvPMYP348V1xxBVFRUQwdOhSz2cy6devYuHEjzz///CnVMH78eLp27Urbtm0pKiril19+oU2bNlW2Xb58OfPmzaNfv34EBwezfPlyDh48aG//zDPPcN999+Hr68uAAQMoKipi5cqVZGZmMnbsWIYPH86rr77KVVddxbPPPktERAR79uxh+vTpPPzww0RERJz5H6aIiChYiIicre677z6ys7N54IEHSE9PJy4ujpkzZxIbG1tl+/vvvx+r1cpll13Gb7/9Rv/+/fnll1949tlnefnll3F2dqZ169bcfvvtp1yDi4sLjz32GLt378bd3Z3zzz+fadOmVdnWx8eHRYsW8eabb5KTk0N0dDSvv/46l156KQC33347Hh4evPrqqzz00EN4enrSvn177r//fgA8PDxYtGgRjzzyCEOGDCE3N5emTZvSp08f9WCIiNQAk2GU36dPRERERETkDGkdCxERERERqTYFCxERERERqTYFCxERERERqTYFCxERERERqTYFCxERERERqTYFCxERERERqTYFixrw7rvv0qxZM9zc3OjZsycrVqxwdEniQIsWLWLgwIGEh4djMpn48ccfK+03DIPx48cTFhaGu7s7ffv2Zdu2bZXaZGRkMHz4cHx8fPDz8+O2224jLy+vUpv169dz/vnn4+bmRmRkJK+88spxtXz33Xe0bt0aNzc32rdvz6xZs2r8+0rdmDBhAt27d8fb25vg4GAGDRpEUlJSpTaFhYWMGjWKwMBAvLy8uPrqq0lLS6vUZu/evVx++eV4eHgQHBzMQw89RGlpaaU2CxYsoEuXLri6utKyZUumTp16XD36vdd4TJo0iQ4dOuDj44OPjw+9evVi9uzZ9v06r6SmvPTSS5hMJvvaMqDzq9ExpFqmTZtmuLi4GJ988omxadMm44477jD8/PyMtLQ0R5cmDjJr1izjiSeeMKZPn24AxowZMyrtf+mllwxfX1/jxx9/NNatW2dceeWVRkxMjHHkyBF7mwEDBhgdO3Y0li1bZixevNho2bKlcf3119v3Z2dnGyEhIcbw4cONjRs3Gl9//bXh7u5ufPDBB/Y2S5YsMSwWi/HKK68YmzdvNp588knD2dnZ2LBhQ63/GUjN69+/vzFlyhRj48aNxtq1a43LLrvMiIqKMvLy8uxt7rrrLiMyMtKYN2+esXLlSuPcc881evfubd9fWlpqtGvXzujbt6+xZs0aY9asWUaTJk2Mxx57zN5m586dhoeHhzF27Fhj8+bNxttvv21YLBbjt99+s7fR773GZebMmcavv/5qbN261UhKSjIef/xxw9nZ2di4caNhGDqvpGasWLHCaNasmdGhQwdjzJgx9u06vxoXBYtq6tGjhzFq1Cj767KyMiM8PNyYMGGCA6uS+uKfwcJqtRqhoaHGq6++at+WlZVluLq6Gl9//bVhGIaxefNmAzASEhLsbWbPnm2YTCZj//79hmEYxnvvvWf4+/sbRUVF9jaPPPKI0apVK/vrYcOGGZdffnmlenr27GnceeedNfodxTHS09MNwFi4cKFhGLbzyNnZ2fjuu+/sbRITEw3AWLp0qWEYttBrNpuN1NRUe5tJkyYZPj4+9nPp4YcfNtq2bVvps6699lqjf//+9tf6vdf4+fv7Gx999JHOK6kRubm5RmxsrDFnzhzjwgsvtAcLnV+Nj4ZCVUNxcTGrVq2ib9++9m1ms5m+ffuydOlSB1Ym9dWuXbtITU2tdM74+vrSs2dP+zmzdOlS/Pz86Natm71N3759MZvNLF++3N7mggsuwMXFxd6mf//+JCUlkZmZaW9T8XOOttG52ThkZ2cDEBAQAMCqVasoKSmp9N+8devWREVFVTq32rdvT0hIiL1N//79ycnJYdOmTfY2Jztv9HuvcSsrK2PatGnk5+fTq1cvnVdSI0aNGsXll19+3Dmg86vxcXJ0AQ3ZoUOHKCsrq3SyA4SEhLBlyxYHVSX1WWpqKkCV58zRfampqQQHB1fa7+TkREBAQKU2MTExxx3j6D5/f39SU1NP+jnScFmtVu6//37i4+Np164dYPvv7uLigp+fX6W2/zy3qjonju47WZucnByOHDlCZmamfu81Qhs2bKBXr14UFhbi5eXFjBkziIuLY+3atTqvpFqmTZvG6tWrSUhIOG6ffm81PgoWIiINzKhRo9i4cSN//fWXo0uRRqJVq1asXbuW7Oxsvv/+e0aMGMHChQsdXZY0cMnJyYwZM4Y5c+bg5ubm6HKkDmgoVDU0adIEi8Vy3N0L0tLSCA0NdVBVUp8dPS9Ods6EhoaSnp5eaX9paSkZGRmV2lR1jIqfcaI2OjcbttGjR/PLL78wf/58IiIi7NtDQ0MpLi4mKyurUvt/nltnet74+Pjg7u6u33uNlIuLCy1btqRr165MmDCBjh078tZbb+m8kmpZtWoV6enpdOnSBScnJ5ycnFi4cCETJ07EycmJkJAQnV+NjIJFNbi4uNC1a1fmzZtn32a1Wpk3bx69evVyYGVSX8XExBAaGlrpnMnJyWH58uX2c6ZXr15kZWWxatUqe5s///wTq9VKz5497W0WLVpESUmJvc2cOXNo1aoV/v7+9jYVP+doG52bDZNhGIwePZoZM2bw559/HjcUrmvXrjg7O1f6b56UlMTevXsrnVsbNmyoFFznzJmDj48PcXFx9jYnO2/0e+/sYLVaKSoq0nkl1dKnTx82bNjA2rVr7Y9u3boxfPhw+3OdX42Mo2ePN3TTpk0zXF1djalTpxqbN282Ro4cafj5+VW6e4GcXXJzc401a9YYa9asMQDjjTfeMNasWWPs2bPHMAzb7Wb9/PyMn376yVi/fr1x1VVXVXm72c6dOxvLly83/vrrLyM2NrbS7WazsrKMkJAQ48YbbzQ2btxoTJs2zfDw8DjudrNOTk7Ga6+9ZiQmJhpPPfWUbjfbgN19992Gr6+vsWDBAiMlJcX+KCgosLe56667jKioKOPPP/80Vq5cafTq1cvo1auXff/R2zb269fPWLt2rfHbb78ZQUFBVd628aGHHjISExONd999t8rbNur3XuPx6KOPGgsXLjR27dplrF+/3nj00UcNk8lk/PHHH4Zh6LySmlXxrlCGofOrsVGwqAFvv/22ERUVZbi4uBg9evQwli1b5uiSxIHmz59vAMc9RowYYRiG7Zaz48aNM0JCQgxXV1ejT58+RlJSUqVjHD582Lj++usNLy8vw8fHx7jllluM3NzcSm3WrVtnnHfeeYarq6vRtGlT46WXXjqulm+//dY455xzDBcXF6Nt27bGr7/+WmvfW2pXVecUYEyZMsXe5siRI8Y999xj+Pv7Gx4eHsbgwYONlJSUSsfZvXu3cemllxru7u5GkyZNjAceeMAoKSmp1Gb+/PlGp06dDBcXF6N58+aVPuMo/d5rPG699VYjOjracHFxMYKCgow+ffrYQ4Vh6LySmvXPYKHzq3ExGYZhOKavREREREREGgvNsRARERERkWpTsBARERERkWpTsBARERERkWpTsBARERERkWpTsBARERERkWpTsBARERERkWpTsKgBRUVFPP300xQVFTm6FGlkdG5JbdG5JbVF55bUFp1b9Z/WsagBOTk5+Pr6kp2djY+Pj6PLkUZE55bUFp1bUlt0bklt0blV/6nHQkREREREqk3BQkREREREqs3J0QXUttLSUtasWUNISAhmc+3kqNzcXAD2799PTk5OrXyGnJ10bklt0bkltUXnltQWnVuOYbVaSUtLo3Pnzjg5nTw6NPo5FgkJCfTo0cPRZYiIiIiINFgrVqyge/fuJ23T6HssQkJCANsfRlhYmIOrERERERFpOFJSUujRo4f9mvpkGn2wODr8KSwsjIiICAdXIyIiIiLS8JzKlAJN3hYRERERkWpTsBARERERkWpTsBARERERkWpr9HMsRERERBqjsrIySkpKHF2GNHDOzs5YLJYaOZZDg8WiRYt49dVXWbVqFSkpKcyYMYNBgwbZ9xuGwVNPPcXkyZPJysoiPj6eSZMmERsb67iiRURERBzIMAxSU1PJyspydCnSSPj5+REaGorJZKrWcRwaLPLz8+nYsSO33norQ4YMOW7/K6+8wsSJE/n000+JiYlh3Lhx9O/fn82bN+Pm5uaAikVEREQc62ioCA4OxsPDo9oXg3L2MgyDgoIC0tPTAaq9NINDg8Wll17KpZdeWuU+wzB48803efLJJ7nqqqsA+OyzzwgJCeHHH3/kuuuuq8tSRURERByurKzMHioCAwMdXY40Au7u7gCkp6cTHBxcrWFR9Xby9q5du0hNTaVv3772bb6+vvTs2ZOlS5ee8H1FRUXk5OTYH0eXfxcRERFp6I7OqfDw8HBwJdKYHD2fqjtnp94Gi9TUVIDjVvkLCQmx76vKhAkT8PX1tT/i4uJqtc5TUlIIhuHoKkRERKSR0PAnqUk1dT7V22Bxph577DGys7Ptj82bNzu2oNxU+Lgv/D3RsXWIiIiIiNSiehssQkNDAUhLS6u0PS0tzb6vKq6urvj4+Ngf3t7etVrnv0qaBakbYM54WP+dY2sRERERaUSaNWvGm2++ecrtFyxYgMlkqvU7ak2dOhU/P79a/Yz6qN4Gi5iYGEJDQ5k3b559W05ODsuXL6dXr14OrOw0dbsVzh1le/7j3bBzgUPLEREREalrJpPppI+nn376jI6bkJDAyJEjT7l97969SUlJwdfX94w+T07OoXeFysvLY/v27fbXu3btYu3atQQEBBAVFcX999/P888/T2xsrP12s+Hh4ZXWumgIjH7PYco9AJtmwDc3wi2zILS9o8sSERERqRMpKSn259988w3jx48nKSnJvs3Ly8v+3DAMysrKcHL698vUoKCg06rDxcXlpCNfpHoc2mOxcuVKOnfuTOfOnQEYO3YsnTt3Zvz48QA8/PDD3HvvvYwcOZLu3buTl5fHb7/91qDWsMgvKmXkF2v4pcVTEH0eFOXAl9dAVrKjSxMRERGpE6GhofaHr68vJpPJ/nrLli14e3sze/ZsunbtiqurK3/99Rc7duzgqquuIiQkBC8vL7p3787cuXMrHfefQ6FMJhMfffQRgwcPxsPDg9jYWGbOnGnf/8+hUEeHLP3++++0adMGLy8vBgwYUCkIlZaWct999+Hn50dgYCCPPPIII0aMOO1/6J40aRItWrTAxcWFVq1a8fnnn9v3GYbB008/TVRUFK6uroSHh3PffffZ97/33nvExsbi5uZGSEgIQ4cOPa3PrisODRYXXXQRhmEc95g6dSpgOzmeffZZUlNTKSwsZO7cuZxzzjmOLPm0fb1iL3M2pzF2+hbWxr8LQW0gNwW+uBoKMhxdnoiIiDRwhmFQUFzqkIdRg3e9fPTRR3nppZdITEykQ4cO5OXlcdlllzFv3jzWrFnDgAEDGDhwIHv37j3pcZ555hmGDRvG+vXrueyyyxg+fDgZGSe+5iooKOC1117j888/Z9GiRezdu5cHH3zQvv/ll1/myy+/ZMqUKSxZsoScnBx+/PHH0/puM2bMYMyYMTzwwANs3LiRO++8k1tuuYX58+cD8MMPP/C///2PDz74gG3btvHjjz/Svr1tdMvKlSu57777ePbZZ0lKSuK3337jggsuOK3PrysOHQp1NrglPoZlOzOYm5jGbd9s4+ebPif8+yvhUBJMGw43zgDnhtMDIyIiIvXLkZIy4sb/7pDP3vxsfzxcauZy8tlnn+U///mP/XVAQAAdO3a0v37uueeYMWMGM2fOZPTo0Sc8zs0338z1118PwIsvvsjEiRNZsWIFAwYMqLJ9SUkJ77//Pi1atABg9OjRPPvss/b9b7/9No899hiDBw8G4J133mHWrFmn9d1ee+01br75Zu655x7ANkpn2bJlvPbaa1x88cXs3buX0NBQ+vbti7OzM1FRUfTo0QOAvXv34unpyRVXXIG3tzfR0dH20T71Tb2dvN1YWMwm3rquE3FhPhzOL+bm6QfIu2YauPrA3r9hxkiwljm6TBERERGH6tatW6XXeXl5PPjgg7Rp0wY/Pz+8vLxITEz81x6LDh062J97enri4+NDenr6Cdt7eHjYQwVAWFiYvX12djZpaWn2i3wAi8VC165dT+u7JSYmEh8fX2lbfHw8iYmJAFxzzTUcOXKE5s2bc8cddzBjxgxKS0sB+M9//kN0dDTNmzfnxhtv5Msvv6SgoOC0Pr+uqMeiDni6OvHxzd246p0lbE3L45657kwZ9gWWr4bC5p/g98dhwEugxW5ERETkNLk7W9j8bH+HfXZN8fT0rPT6wQcfZM6cObz22mu0bNkSd3d3hg4dSnFx8UmP4+zsXOm1yWTCarWeVvuaHOJ1KiIjI0lKSmLu3LnMmTOHe+65h1dffZWFCxfi7e3N6tWrWbBgAX/88Qfjx4/n6aefJiEhod7d0lY9FnUkzNedj0d0x93ZwqKtB3lmYyAMmmTbufx9+PttxxYoIiIiDZLJZMLDxckhj9pcAXzJkiXcfPPNDB48mPbt2xMaGsru3btr7fOq4uvrS0hICAkJCfZtZWVlrF69+rSO06ZNG5YsWVJp25IlS4iLi7O/dnd3Z+DAgUycOJEFCxawdOlSNmzYAICTkxN9+/bllVdeYf369ezevZs///yzGt+sdqjHog61j/Dlf9d24u4vV/HZ0j00b9KVm/u9AH88AXPGgXcYdLjG0WWKiIiIOFxsbCzTp09n4MCBmEwmxo0bd9Keh9py7733MmHCBFq2bEnr1q15++23yczMPK1Q9dBDDzFs2DA6d+5M3759+fnnn5k+fbr9LldTp06lrKyMnj174uHhwRdffIG7uzvR0dH88ssv7Ny5kwsuuAB/f39mzZqF1WqlVatWtfWVz5h6LOrYgHahPDKgNQDP/rKZ+QHD4FzbRB7bAnoLHVidiIiISP3wxhtv4O/vT+/evRk4cCD9+/enS5cudV7HI488wvXXX89NN91Er1698PLyon///qe1/MGgQYN46623eO2112jbti0ffPABU6ZM4aKLLgLAz8+PyZMnEx8fT4cOHZg7dy4///wzgYGB+Pn5MX36dC655BLatGnD+++/z9dff03btm1r6RufOZNR14PI6ti+ffuIjIwkOTmZiIgIR5cD2G4L98gP6/l25T48XSx8f9e5tFlyv20BPVcfuGU2hLZzdJkiIiJSzxQWFrJr1y5iYmIa1LpejYnVaqVNmzYMGzaM5557ztHl1IiTnVency2tHgsHMJlMPD+oPb2aB5JfXMZtn64ive+bEB1fvoDeUC2gJyIiIlIP7Nmzh8mTJ7N161Y2bNjA3Xffza5du/i///s/R5dW7yhYOIiLk5lJN3SheRNPDmQXcsdXmyi8+vPKC+gdyXR0mSIiIiJnNbPZzNSpU+nevTvx8fFs2LCBuXPn0qZNG0eXVu8oWDiQn4cLH9/cHT8PZ9YlZ/HAz3uw/t934B1uW0Dv6/+DkkJHlykiIiJy1oqMjGTJkiVkZ2eTk5PD33//XW9XvnY0BQsHi2niyQc3dMXZYuLXDSm8saIAbvj+Hwvo1f0dEEREREREToeCRT3Qs3kgE4bYVol8Z/52ftjnC9d9CRaX8gX0HoPGPcdeRERERBo4BYt6YmjXCO65yLac/KPT17PcaKsF9ERERESkwVCwqEce7NeKy9qHUlJmcOcXq9gddin0e962c8442PC9YwsUERERETkBBYt6xGw28fo1negY4UtWQQm3Tk0gu+OdxxbQm3GXFtATERERkXpJwaKecXexMPmmboT7urHzUD53f7Wakr7PQdwgsJbANzdA6kZHlykiIiIiUomCRT0U7OPGxzd3x9PFwt87DjPup80Yg9/XAnoiIiJyVrvooou4//777a+bNWvGm2++edL3mEwmfvzxx2p/dk0d52SefvppOnXqVKufUZsULOqpNmE+vP1/nTGbYFpCMpOXHrDdKeroAnpfDtUCeiIiItIgDBw4kAEDBlS5b/HixZhMJtavX3/ax01ISGDkyJHVLa+SE13cp6SkcOmll9boZzU2Chb12CWtQ3jy8jgAJszewu87i2xrXHiHw8EtWkBPREREGoTbbruNOXPmsG/fvuP2TZkyhW7dutGhQ4fTPm5QUBAeHh41UeK/Cg0NxdXVtU4+q6FSsKjnbolvxg3nRmEYcP+0tWzM89YCeiIiItKgXHHFFQQFBTF16tRK2/Py8vjuu++47bbbOHz4MNdffz1NmzbFw8OD9u3b8/XXX5/0uP8cCrVt2zYuuOAC3NzciIuLY86cOce955FHHuGcc87Bw8OD5s2bM27cOEpKSgCYOnUqzzzzDOvWrcNkMmEymew1/3Mo1IYNG7jkkktwd3cnMDCQkSNHkpeXZ99/8803M2jQIF577TXCwsIIDAxk1KhR9s86FVarlWeffZaIiAhcXV3p1KkTv/32m31/cXExo0ePJiwsDDc3N6Kjo5kwYQIAhmHw9NNPExUVhaurK+Hh4dx3332n/NlnwqlWjy7VZjKZeHpgW/YcLmDxtkPc9mkCP406j9DrvoTPh5QvoPc4DJgAJpOjyxUREZG6ZhhQUuCYz3b2OKXrDycnJ2666SamTp3KE088gan8Pd999x1lZWVcf/315OXl0bVrVx555BF8fHz49ddfufHGG2nRogU9evT418+wWq0MGTKEkJAQli9fTnZ2dqX5GEd5e3szdepUwsPD2bBhA3fccQfe3t48/PDDXHvttWzcuJHffvuNuXPnAuDr63vcMfLz8+nfvz+9evUiISGB9PR0br/9dkaPHl0pPM2fP5+wsDDmz5/P9u3bufbaa+nUqRN33HHHv34fgLfeeovXX3+dDz74gM6dO/PJJ59w5ZVXsmnTJmJjY5k4cSIzZ87k22+/JSoqiuTkZJKTbfNwf/jhB/73v/8xbdo02rZtS2pqKuvWrTulzz1TChYNgJPFzLvDu3D1e3+zLT2P2z5N4Ns7e+M5+H344TZYPgl8m0Lvex1dqoiIiNS1kgJ4Mdwxn/34AXDxPKWmt956K6+++ioLFy7koosuAmzDoK6++mp8fX3x9fXlwQcftLe/9957+f333/n2229PKVjMnTuXLVu28PvvvxMebvvzePHFF4+bF/Hkk0/anzdr1owHH3yQadOm8fDDD+Pu7o6XlxdOTk6Ehoae8LO++uorCgsL+eyzz/D0tH3/d955h4EDB/Lyyy8TEhICgL+/P++88w4Wi4XWrVtz+eWXM2/evFMOFq+99hqPPPII1113HQAvv/wy8+fP58033+Tdd99l7969xMbGct5552EymYiOjra/d+/evYSGhtK3b1+cnZ2Jioo6pT/H6tBQqAbCx82ZT27uTqCnC5sO5HD/N2spa3v1sQX0/nhSC+iJiIhIvdW6dWt69+7NJ598AsD27dtZvHgxt912GwBlZWU899xztG/fnoCAALy8vPj999/Zu3fvKR0/MTGRyMhIe6gA6NWr13HtvvnmG+Lj4wkNDcXLy4snn3zylD+j4md17NjRHioA4uPjsVqtJCUl2be1bdsWi8Vifx0WFkZ6evopfUZOTg4HDhwgPj6+0vb4+HgSExMB23CrtWvX0qpVK+677z7++OMPe7trrrmGI0eO0Lx5c+644w5mzJhBaWnpaX3P06UeiwYkMsCDD2/qxvWTlzFncxov/7aFxy8dDdn7bb0WM+4CzyBofqGjSxUREZG64uxh6zlw1Gefhttuu417772Xd999lylTptCiRQsuvNB23fLqq6/y1ltv8eabb9K+fXs8PT25//77KS4urrFyly5dyvDhw3nmmWfo378/vr6+TJs2jddff73GPqMiZ2fnSq9NJhPWGpwb26VLF3bt2sXs2bOZO3cuw4YNo2/fvnz//fdERkaSlJTE3LlzmTNnDvfcc4+9x+ifddUU9Vg0MF2j/Xl1qO2uCR8u2sm0hGTo/6IW0BMRETlbmUy24UiOeJzm/M5hw4ZhNpv56quv+Oyzz7j11lvt8y2WLFnCVVddxQ033EDHjh1p3rw5W7duPeVjt2nThuTkZFJSUuzbli1bVqnN33//TXR0NE888QTdunUjNjaWPXv2VGrj4uJCWVnZv37WunXryM/Pt29bsmQJZrOZVq1anXLNJ+Pj40N4eDhLliyptH3JkiXExcVVanfttdcyefJkvvnmG3744QcyMjIAcHd3Z+DAgUycOJEFCxawdOlSNmzYUCP1VUXBogG6qlNT7u8bC8CTP25kyc4MGPyBFtATERGRes3Ly4trr72Wxx57jJSUFG6++Wb7vtjYWObMmcPff/9NYmIid955J2lpaad87L59+3LOOecwYsQI1q1bx+LFi3niiScqtYmNjWXv3r1MmzaNHTt2MHHiRGbMmFGpTbNmzdi1axdr167l0KFDFBUVHfdZw4cPx83NjREjRrBx40bmz5/Pvffey4033mifX1ETHnroIV5++WW++eYbkpKSePTRR1m7di1jxowB4I033uDrr79my5YtbN26le+++47Q0FD8/PyYOnUqH3/8MRs3bmTnzp188cUXuLu7V5qHUdMULBqoMX1iuapTOKVWg7u+WMX2zNLyBfRaawE9ERERqbduu+02MjMz6d+/f6X5EE8++SRdunShf//+XHTRRYSGhjJo0KBTPq7ZbGbGjBkcOXKEHj16cPvtt/PCCy9UanPllVfy3//+l9GjR9OpUyf+/vtvxo0bV6nN1VdfzYABA7j44osJCgqq8pa3Hh4e/P7772RkZNC9e3eGDh1Knz59eOedd07vD+Nf3HfffYwdO5YHHniA9u3b89tvvzFz5kxiY23/wOzt7c0rr7xCt27d6N69O7t372bWrFmYzWb8/PyYPHky8fHxdOjQgblz5/Lzzz8TGBhYozVWZDIMw6i1o9cD+/btIzIykuTkZCIiIhxdTo0qLClj+EfLWbUnk6gAD34cFU9AaTp81NcWLqLj4Ybp4Ozm6FJFRESkBhQWFrJr1y5iYmJwc9Pf71IzTnZenc61tHosGjA3Zwsf3NiVCH939mYUcOfnKynyDIPh5Qvo7VkCM+7UAnoiIiIiUusULBq4Jl6uTLm5O96uTiTszuSxHzZghLS1DYsyO8PmH20L6DXujikRERERcTAFi0YgNsSb927ogsVsYvqa/bw7fzvEXACD37c1WD4JltbsmD8RERERkYoULBqJ82ODeObKtgC89sdWfll/ANoPhf88Z2ugBfREREREpBYpWDQiN5wbza3xMQA88O061uzNhN73Qs+7bQ1m3AW7FjmwQhERERFprBQsGpknLm9Dn9bBFJVaueOzlezLOlK+gN5VtgX0pg2HtE2OLlNERESqoSZXbxapqfPJqUaOIvWGxWzires7M3TS32xJzeW2qSv5/u5eeA/+EPIOwt6/4YuhcPsc8G1ct98VERFp7FxcXDCbzRw4cICgoCBcXFzsK1eLnC7DMCguLubgwYOYzWZcXFyqdTytY9FIHcg6wlXvLuFgbhEXtQrio5u64VScDZ8MgINbIKgN3Dob3P0dXaqIiIichuLiYlJSUigoKHB0KdJIeHh4EBYWVmWwOJ1raQWLRmz9viyGfbCUwhIrN/duxtNXtoWsZPj4P1pAT0REpAEzDIPS0lLKysocXYo0cBaLBScnpxP2fJ3OtbSGQjViHSL8ePPaTtz1xWqm/r2b5kGe3NSrmW0BvSmXHltAb+gUMGu6jYiISENhMplwdnbG2dnZ0aWI2OlqspEb0C6Mhwe0AuDpmZtYkJQOoe3g2i+OLaD3491QVuLYQkVERESkQVOwOAvcfWELrukagdWA0V+tISk1F5pfCEM+BJMF1k+Daf8HxfmOLlVEREREGigFi7OAyWTihcHt6RkTQF5RKbdOTeBgbhG0GwLXfw1O7rDtD/jsKijIcHS5IiIiItIAKVicJVyczLx/Q1dimniyP+sId3y2ksKSMjinP9z0E7j5wb4E29yL7P2OLldEREREGhgFi7OIv6cLH4/ohq+7M2uTs3jwu3VYrQZE9YRbfwPvcNutaD/uBweTHF2uiIiIiDQgChZnmeZBXrx/Q1ecLSZ+WZ/Cm3O32nYEt4Hb/oDAWMjZB5/0h30rHVusiIiIiDQY9TpYlJWVMW7cOGJiYnB3d6dFixY899xzNPKlN2pdrxaBvDC4PQAT/9zOtBV7bTv8IuHW36FpVziSCZ8OhG1zHVipiIiIiDQU9TpYvPzyy0yaNIl33nmHxMREXn75ZV555RXefvttR5fW4A3rFsndF7UA4LEZG/hh1T7bDs9AuGkmtOgDJQXw9bWw/lsHVioiIiIiDUG9DhZ///03V111FZdffjnNmjVj6NCh9OvXjxUrVji6tEbh4f6tuPHcaAwDHvp+HT+tLZ+07eoF10+DdkPBWgrT74Cl7zm2WBERERGp1+p1sOjduzfz5s1j61bbPIB169bx119/cemll57wPUVFReTk5Ngfubm5dVVug2MymXjmyrZc3yMSqwFjv13HrA0ptp1OLjBkMvS82/b698dg7tOgYWgiIiIiUgUnRxdwMo8++ig5OTm0bt0ai8VCWVkZL7zwAsOHDz/heyZMmMAzzzxTh1U2bGaziRcGtaekzOD7Vfu47+s1OJlN9GsbCmYzDJgAXkEw71n463+QfxCueAss9frUEREREZE6Vq97LL799lu+/PJLvvrqK1avXs2nn37Ka6+9xqeffnrC9zz22GNkZ2fbH5s3b67Dihsms9nEy1d3YFCncEqtBqO+Ws2fW9JsO00mOP8BGDgRTGZY8wV8eyOUHHFs0SIiIiJSr5iMenyLpcjISB599FFGjRpl3/b888/zxRdfsGXLllM6xr59+4iMjCQ5OZmIiIjaKrVRKC2zMuabtfy6PgUXi5nJI7px4TlBxxps+RW+vxVKCyGqt23Vbnc/h9UrIiIiIrXrdK6l63WPRUFBAWZz5RItFgtWq9VBFTVuThYzb17bif5tQyguszLys5X8vf3QsQatL4cbZ4CrL+z9G6ZcBjkpjitYREREROqNeh0sBg4cyAsvvMCvv/7K7t27mTFjBm+88QaDBw92dGmNlrPFzNvXd6FP62CKSq3c9ulKlu88fKxBdG+4ZRZ4hUL6Jtsq3Ye2O65gEREREakX6nWwePvttxk6dCj33HMPbdq04cEHH+TOO+/kueeec3RpjZqLk5n3bujChecEcaSkjFumJrBqT8axBqHt4LbfIaAFZO+FT/rB/tWOK1hEREREHK5ez7GoCZpjceYKS8q4/dOV/LX9EN6uTnx+e086Rfoda5B3EL4cCilrwcULrv0CWlzsqHJFREREpIY1mjkW4lhuzhYm39SNc5sHkFtUyk0fL2fj/uxjDbyC4OZfIOZCKM6DL6+BjT84rmARERERcRgFCzkpdxcLH4/oTrdof3IKS7nh4+VsPpBzrIGrNwz/DtoOBmsJfH8bLP/QcQWLiIiIiEMoWMi/8nR1Ysot3ekc5UdWQQk3fLycrWkVVjR3coWrP4budwAGzH4I/nxBq3SLiIiInEUULOSUeLs5M/WWHnSI8CUjv5j/m7yc7el5xxqYLXDZq3DR47bXi16BX+4Ha5lD6hURERGRuqVgIafM192Zz27tQVyYD4fyivi/ycvYdSj/WAOTCS56BC5/AzDBqqnw3QgoKXRUySIiIiJSRxQs5LT4ebjwxe09aRXiTXquLVzsPVxQuVH322DYp2BxgcSfbXeOKsyu+oAiIiIi0igoWMhpC/B04cs7etIy2IuU7EKun7yMfZn/CBdxV8ENP4CLN+xeDFMvh9w0xxQsIiIiIrVOwULOSBMvV766vSfNm3iyP+sI/zd5OSnZRyo3irkAbvkVPIMgdYNtIb2MnY4pWERERERqlYKFnLFgHze+uuNcogM92JtRwP9NXk56zj/mU4R1hFt/B/9mkLkbPu4PKescUa6IiIiI1CIFC6mWUF9buIjwd2fXoXyun7yMg7lFlRsFtoBb/4CQ9pCfDlMuh12LHVOwiIiIiNQKBQuptqZ+7nx9x7mE+bqx42A+N3y0nIz84sqNvENsw6Kiz4PiXPhiCGye6ZiCRURERKTGKVhIjYgM8ODrO84l2NuVpLRchn+0nKyCf4QLN1/bhO7WV0BZse1WtCs/cUzBIiIiIlKjFCykxjRr4snXI8+liZcriSk53PjxCrKPlFRu5OwGwz6DLiPAsMIv/4UFL2uVbhEREZEGTsFCalSLIC++vqMngZ4ubNifzYhPVpBb+I9wYbbAwLfggodsrxe8CLMe0irdIiIiIg2YgoXUuNgQb764vSd+Hs6sTc7ilikJ5BeVVm5kMsElT8KlrwAmSJgMP9wGpUVVHlNERERE6jcFC6kVbcJ8+OK2nvi4ObFyTya3Tk2goLj0+IY974SrPwKzM2yaAV9eA0W5dV+wiIiIiFSLgoXUmnZNffn8tp54uzqxfFcGd3y2ksKSKoY7tR8Kw78FZ0/YtRCmXgF5B+u+YBERERE5YwoWUqs6Rvox9dYeeLpYWLL9MCM/X1V1uGhxCdz8M3gEQspa+KS/bUE9EREREWkQFCyk1nWN9mfKLT1wd7awaOtBRn25muJS6/ENm3a1rdLtGwUZO+D9C2D6SNsQqcKcui9cRERERE6ZgoXUiR4xAXx8czdcnczM25LOvV+vpqSsinDRJBZu+922SndRNqz/Br67GV5pDp8PhhWTISu5zusXERERkZMzGUbjXkBg3759REZGkpycTEREhKPLOest2nqQ2z9bSXGplcs7hPHWtZ1wslSRb8tKYd8KSJoFW2bZejAqCm0PrS6DVpdCWCfbXaZEREREpEadzrW0goXUuflb0rnz81UUl1m5qlM4bwzrhMX8L8Hg0DZbyEiaDcnLbYvrHeUdDq0G2IJGzAXg5Fq7X0BERETkLKFgUYGCRf00Z3Mad3+xilKrwdVdInh1aAfM/xYujso/BNv+sAWN7X9CSf6xfS5etongrS6D2H7gGVg7X0BERETkLKBgUYGCRf01e0MKo79eQ5nV4Lrukbw4uP2ph4ujSgph9+JjvRm5Kcf2mcwQea5tuFSry6BJy5r9AiIiIiKNnIJFBQoW9dvMdQe4f9oarAbceG40z17VFtOZzpcwDNutapNm24JG6obK+wNjj4WMyB5gtlS7fhEREZHG7HSupZ3qqCaRKl3ZMZzSMisPfLeOz5ftwcliYvwVcWcWLkwmCO9se1z8OGTtha2/20LGrsVweBv8vQ3+ngjuAXDOAFvQaHEJuHrV/JcTEREROYsoWIjDDekSQWmZwcM/rGfKkt24WMw8emnrM++5OMovCnrcYXsU5sCOebbejK2/w5EMWPeV7WFxgZgLy3szLgWf8Jr5YiIiIiJnEQULqReGdY+k1Grw+IwNfLBoJ04WEw/2a1X9cHGUmw+0HWx7lJXC3qXHhkxl7oLtc2yPX8fabl979Fa2oe11K1sRERGRU6A5FlKvfPr3bp6auQmA0Re3ZEzfWJyrWueiphgGHEw6Nvl7XwJQ4X8Jn4hjPRnNzgcnl9qrRURERKSe0eTtChQsGp6PFu/k+V8TAYgK8GDUxS0Y0iWidgPGUXnp5fMyZsOOP6H0yLF9Lt7Qso+tNyOgOZjNYLKA2ck2EdxkKf9pPn5bpf1HtzmpN0RERETqNQWLChQsGqZpK/by6u9JHM4vBqCpnzujLm7J0K4RuDjVQcAAKDkCOxfaejO2/gZ5abXwIaYKYcOpQjA5jW1mp2NhxckVAltCcByEtIXgNuDqXQt1i4iIyNlAwaICBYuGq6C4lK+W7+X9hTs5lFcEQLivG3df1IJh3SNxdarD28VarXBgTfmifHPhSKZt9W9rKVjLwCiz/az43Ciz7Xc03ygIiascNgJjNaxLRERE/pWCRQUKFg1fYUkZX6/Yy6QFO0jPtQWMUB9bwLi2eyRuzvV8PQqr9R9hozxwGNbKAcRadoJtZRWO8Y9t1tLKxy7Kg4NbID0R0jdXXjCwIrMzNIm1hY3gNuWBI852Jy0NzxIREZFyChYVKFg0HoUlZXy7Mpn35u8gNacQgGBvV+68sAX/1yMKd5d6HjAcoSDDFjDSEyFt07HnRTlVt3fxtgWNimEjpC14BNRt3SIiIlIvKFhUoGDR+BSVlvHtyn1Mmr+dA9m2gNHEy5U7L2jO8HOj8HDRXZRPyjAge58tZFQMGweTwFpS9Xu8QioMpSrv5QhqDS4edVu7iIhIQ1FWAsX5tjmbJQXlzwtOsK3A9vNE24ZOAb9Ih3wNBYsKFCwar+JSKz+s3se787ezL9N296ZATxfuuKA5N54bjaerAsZpKSuBw9vLw0biseCRtecEbzDZ7o51dP7G0eAR0Nw2kVxERKS+s1ptvfiFWbYL+n+7wC8ugJJ/tqu47cix5yf6x7ozcddftrW1HEDBogIFi8avpMzKjNX7eWf+dvZmFADg7+HM7ec356Ze0Xi7OTu4wgauKNfWm3G0d+Poz4LDVbd3coOgVhXCRhwEtwXvUM3fEBGR2lFWagsHRzJP8VHetjDLNr+xNpks4OIJzh62nn5nT3B2P/bcxaN8X/l2+/MK26Ljwd2vdus8AQWLChQszh4lZVZ+WnuAd/7cxu7DtoDh6+7M7efFMCK+GT4KGDXHMCD/YIWhVJshbbNt4nhJQdXvcXKz3frWxQtcvWzzOVy9zuy1i6dCiohIY1RSeHwI+NfAkHXiuYOnqtKF/T8v9j0qhIKK29xPEBj+sc3i3KD/zlKwqEDB4uxTWmbl5/UHePvP7ew8mA+Aj5sTt54Xwy3xMfi6K2DUGqsVMndVHkqVvtk2xKpG/0XIVCFwVPzpfWavnVwb9C99ERGHKSuxDf8pLaz6Z8kR22KzJYW2n4U5VfccHH1UXJj2TLj5grt/1Q83vxPs87P9PSBVUrCoQMHi7FVmNfilPGBsT88DwNvViVvim3HreTH4eWgdhzpTUgh5qbbb4Rbnlf/M/ZfX/3h+tE1tdFmbzODkDs5utn9lcnIr/1er8odTxecn2Wd/fZLjKMSIyKkyDNsD49hrTmFbWcmJL/RPGgDOoK1RVvPf22SpfNF/oqBwXHDw1Ry/WqBgUYGChVitBrM2pvD2vO0kpeUC4OliYUTvZtx+fnMCPBUwGgzDsP1FVpxnm/tRKXj82+sqwktJvgO+hKlCQPEoDyFVhZcK3eyVHl4nf25xUXCR+s0wbMNWTvav1hVflxVT6cL5uJ9Usb2qbad7jNP4Cccf4+h3PdNtDdHRf1ip9LPi7zU3cPX997Dg6q3fY/WIgkUFChZylNVq8PumVN6at40tqbaA4eFi4cZe0Yw8vzmBXuoGPetYy47d9q/0yLF/iav0utA2b6S0/GdVr0+27+gtBWvjX/WqYnb6lwBSxb6jY4ZP1M7ZA8zmmq2z0gKPpf9Yub70HwtJlp5gW1nlRSKPvjY72VaWt7jaeogsLrafTq7HbzM76QLmTJWVQmH2mY2Hr6v/H85qpuN7Uu0/3Sr3wFbsXa0yHFQVFv6xTb2xjZaCRQUKFvJPVqvBnMQ0Js7bxqYDtsle7s4Wbjg3ipEXtCDIWwFDasHRccgVxxtXFUIqBZzy2x1WfJRUfJ137HlpYe3W7/yPwGFxPrWL/Cpfl9ZurafFVCFwuBz76eR2LHzYf/6jTaWQ4naSfRV+YrJdfJnMx57/82eV207U3nzsYu602v9jX1nxye+cU+Vk2ezq/dFbXG2Lb/5zrPs/x8RX/HOr8if/sv9Uf1bzOPb/BlSxrap2p7uNU3+v2aLeS6kxjSpY7N+/n0ceeYTZs2dTUFBAy5YtmTJlCt26dTul9ytYyIkYhsG8xHQm/rmN9ftsf0G6OpkZ3jOauy5sTrCPm4MrFDkNZaUnDh0nfP5v+/JxyLAMs1N5T4Kl/Lm56tcnamMttV0olxZBWZHtZ2nRsW361/Ka5eJ9+mPh3f1s/+otIvXe6VxL1+sVxDIzM4mPj+fiiy9m9uzZBAUFsW3bNvz9/R1dmjQCJpOJvnEh9GkTzIKkg7w1bxtrk7P4ZMkuvli+h//rEcVdF7Yg1FcBQxoAixNYfG2TF2uK1WrrQSkuOD6AlBWXX9BbKlzcl/80VbjwP26bpUIgsBx7bd9Ww0OuqvxeZRVCR/E/wkfFbRX2lRXbeoVOuK9im39uq/Cz0vh8a9Vj/A3rP9pV1b7C+06r/QnG8JvM5XfM8TuNcOBvO98sutOeiNjU6x6LRx99lCVLlrB48eIzPoZ6LORUGYbB4m2HeGveNlbtyQTAxWLm2u6R3HVRC5r66V/XRKSRMP4RNkzmugl1ItLgnM61dL3+LTJz5ky6devGNddcQ3BwMJ07d2by5MmOLksaKZPJxAXnBPH9Xb348vae9GgWQHGZlc+X7eGiV+fz+IwNJGecYPE3EZGGxGQqHz5msfV2KVSISA2o1z0Wbm62IShjx47lmmuuISEhgTFjxvD+++8zYsSIKt9TVFREUVGR/fX+/fuJi4tTj4WcNsMwWLrzMBPnbWPZzgwAnMwmru4SweAuTTknxFu3qhUREZFGrdFM3nZxcaFbt278/fff9m333XcfCQkJLF26tMr3PP300zzzzDPHbVewkOpYvvMwE//cxpLthyttb+LlQmywN61CvYkN8eKcEG/OCfbG10NjjkVERKThazSTt8PCwoiLi6u0rU2bNvzwww8nfM9jjz3G2LFj7a+P9liIVEfP5oF82TyQlbsz+PivXazfl83+rCMcyivmUN5hlu6sHDiCvV05J6RC2AjxIjbEGx83BQ4RERFpnOp1sIiPjycpKanStq1btxIdHX3C97i6uuLqemwdgpycnFqrT84+3ZoF0K1ZAAD5RaVsS89ja1ou29Jy2ZqWx7a0XA5kF5KeW0R6bhF/bT9U6f2hPm6VwoYtfHjj5Vqv/1cUERER+Vf1+mrmv//9L7179+bFF19k2LBhrFixgg8//JAPP/zQ0aWJ4OnqRKdIPzpF+lXanltYwrb0PHvYsAWPPFJzCu2PxdsqB46mfu72wBEb7GXv7fBwqdf/i4qIiIjY1es5FgC//PILjz32GNu2bSMmJoaxY8dyxx13nPL7dbtZqS+yj5RUDhvptucHc4tO+J4If/djQ6rK53K0CPLC3cVSh5WLiIjI2arRTN6uCQoWUt9lFRRX6NkoH1KVnsuhvOIq25tMEBXgQWxwxeFUXrQI8sLNWYFDREREak6jmbwtcjbw83ChR0wAPWICKm3PyC+uFDaSyp9nFpSw53ABew4XMDcxzd7ebIKYJp70bxvKkC5NaRnsXddfRURERM5i6rEQaUAMw+BQXnF52Mhla4W5HNlHSiq17RDhy5DOTRnYMZxAL9cTHFFERETkxNRjIdJImUwmgrxdCfJ2pXfLJvbthmFwMLeIFbsz+HHNfhYkHWT9vmzW78vm+V8TuahVEEO6RHBJ62ANlxIREZFaoWAh0giYTCaCfdy4okM4V3QI53BeET+vO8D0NftZvy+buYnpzE1Mx8fNics7hHN1l6Z0jfbHZDI5unQRERFpJDQUSqSR256ey/TV+5mxZj8p2YX27dGBHgzq1JQhXZoSHejpwApFRESkvqr1u0IlJydjMpnsB1+xYgVfffUVcXFxjBw58syqriUKFiI2VqvBsp2Hmb5mP7M3pJBfXGbf1y3an8FdmnJF+3B8PbQ6uIiIiNjUerA4//zzGTlyJDfeeCOpqam0atWKtm3bsm3bNu69917Gjx9/xsXXNAULkeMVFJfyx6Y0pq/Zz1/bDmIt/y3gYjHTNy6YwZ0juKhVEM4Ws2MLFREREYeq9cnbGzdupEePHgB8++23tGvXjiVLlvDHH39w11131atgISLH83BxYlDnpgzq3JS0nEJ+Wruf6av3syU1l1kbUpm1IZUATxeu7BjO4M5N6RDhq/kYIiIiclJnFCxKSkpwdbXdvnLu3LlceeWVALRu3ZqUlJSaq05Eal2IjxsjL2jByAtasPlADtNX7+OndQc4mFvE1L93M/Xv3bQI8mRIlwgGdW5KUz93R5csIiIi9dAZjXNo27Yt77//PosXL2bOnDkMGDAAgAMHDhAYGFijBYpI3YkL9+HJK+JY+uglTL2lO1d2DMfN2cyOg/m8+nsS5738J9d/uIzvViaTV1Tq6HJFRESkHjmjORYLFixg8ODB5OTkMGLECD755BMAHn/8cbZs2cL06dNrvNAzpTkWItWTW1jC7I2pTF+9j2U7M+zb3ZzN5at8RxDfIhAnzccQERFpdGp98jZAWVkZOTk5+Pv727ft3r0bDw8PgoODz+SQtULBQqTm7Mss4Ke1B/hh9T52Hsy3bw/ydmVQp3CGdImgTZiPAysUERGRmlTrweLIkSMYhoGHhwcAe/bsYcaMGbRp04b+/fufWdW1RMFCpOYZhsH6fdlMX72PmesOkFlQYt/XOtSbq7tEcFWncIJ93BxYpYiIiFRXrQeLfv36MWTIEO666y6ysrJo3bo1zs7OHDp0iDfeeIO77777jIuvaQoWIrWruNTKgqR0ZqzZz7zEdIrLrACYTXBebBBXd2lKv7hQ3F0sDq5URERETtfpXEuf0aDo1atXc/755wPw/fffExISwp49e/jss8+YOHHimRxSRBooFycz/dqGMumGrqx4og/PD2pH12h/rAYs2nqQMdPW0u35OTw2fT0Hso44ulwRERGpJWd0u9mCggK8vb0B+OOPPxgyZAhms5lzzz2XPXv21GiBItJw+Hm4cMO50dxwbjS7DuUzY81+ZqzZR3LGEb5ekcz01fu57bwY7r6oBd5uWuFbRESkMTmjHouWLVvy448/kpyczO+//06/fv0ASE9Px8dHEzdFBGKaeDL2P+ew6KGLmTbyXHrEBFBUauW9BTu46NUFfL50NyXlw6ZERESk4TujYDF+/HgefPBBmjVrRo8ePejVqxdg673o3LlzjRYoIg2byWTi3OaBfDPyXD68sSvNgzw5nF/MuJ820f9/i/hjUypneHM6ERERqUfO+HazqamppKSk0LFjR8xmWz5ZsWIFPj4+tG7dukaLrA5N3hapX0rKrExbsZf/zd1GRn4xAD1iAnjisjZ0jPRzbHEiIiJSSZ2sY1Hxw4B6e9GuYCFSP+UUlvD+gh18/NcuikptQ6Ku7BjOQ/1bERng4eDqREREBOrgrlBWq5Vnn30WX19foqOjiY6Oxs/Pj+eeew6rVWOmReTf+bg58/CA1sx/8CKGdGmKyQQz1x2gz+sLeXFWItkV1sYQERGR+u+MgsUTTzzBO++8w0svvcSaNWtYs2YNL774Im+//Tbjxo2r6RpFpBEL93PnjWGd+Hn0efRuEUhxmZUPF+3kwtfm88lfuygu1T9WiIiINARnNBQqPDyc999/nyuvvLLS9p9++ol77rmH/fv311iB1aWhUCINh2EYLEg6yIuzEtmWngdAdKAHjwxozaXtQjGZTA6uUERE5OxS60OhMjIyqpyg3bp1azIyMs7kkCIimEwmLm4dzOwx5zNhSHuaeLmy53AB93y5mqsn/c2qPZmOLlFERERO4IyCRceOHXnnnXeO2/7OO+/QoUOHahclImc3J4uZ63tEsfChi7ivTyzuzhZW783i6kl/c8+Xq9h9KN/RJYqIiMg/nNFQqIULF3L55ZcTFRVlX8Ni6dKlJCcnM2vWLM4///waL/RMaSiUSMOXllPIG39s5dtVyRgGOFtM3HBuNPddEou/p4ujyxMREWm0an0o1IUXXsjWrVsZPHgwWVlZZGVlMWTIEDZt2sTnn39+RkWLiJxIiI8bLw/twOwx53PhOUGUlBlMWbKbC16dz4eLdlBYUuboEkVERM561V7HoqJ169bRpUsXysrqz1/y6rEQaXwWbzvIC78msiU1F4Cmfu48PKAVAzuEYzZrgreIiEhNqfUeCxERRzo/Nohf7zufV4d2IMTHlf1ZRxgzbS2D31vC8p2HHV2eiIjIWUnBQkQaJIvZxDXdIlnw4MU88J9z8HSxsG5fNtd+uIw7PlvJjoN5ji5RRETkrKJgISINmruLhXv7xLLgoYsZ3jMKi9nEnM1p9PvfIsb9uJFDeUWOLlFEROSs4HQ6jYcMGXLS/VlZWdWpRUTkjAV5u/LC4PbcEt+Ml2ZvYW5iOp8v28OMNfu5+6IW3HZeDG7OFkeXKSIi0midVrDw9fX91/033XRTtQoSEamOlsHefDSiO0t3HObFWYls2J/Nq78n8cWyPTzYrxWDOzfVBG8REZFaUKN3haqPdFcokbOX1Wowc90BXv09if1ZRwBoG+7D45e1Ib5lEwdXJyIiUv/prlAiIoDZbGJQ56bMe+BCHhnQGm9XJzYdyGH4R8u5ZcoKtqblOrpEERGRRkPBQkQaPTdnC3df1IKFD1/Mzb2b4WQ2MT/pIAPeXMRj09ezPT2PRt55KyIiUus0FEpEzjo7D+bxym9J/LYp1b4tyNuVnjEB9GweyLkxAbQM9sJk0lwMERE5u53OtfRpTd4WEWkMmgd58f6NXUnYncHEedtYviuDg7lF/LI+hV/WpwAQ6OlCj5gAzm0eSM/mAZwT7K1J3yIiIiehYCEiZ63uzQL4/LaeFJaUsS45i2U7M1i+6zCr92ZyOL+Y2RtTmb3R1qvh5+FMj2a2Ho2eMQG0CfPBoqAhIiJip2AhImc9N2eLLTA0DwRiKS61sn5fFst3ZbBs52FW7ckkq6CEPzan8cfmNAB83JzoERNAzxhbj0ZcmA9OFk1bExGRs5fmWIiI/IuSMisb9mezvLxHY+XuTPKKSiu18XJ1onszf3uPRrumvjgraIiISAOnORYiIjXI2WKmS5Q/XaL8ufuiFpSWWdmcksOynYdZvjODFbszyC0sZX7SQeYnHQTAw8VC12h/zm0eyLnNA2jf1A8XJwUNERFpvBQsREROk5PFTIcIPzpE+DHyghaUWQ0SU3LsQ6dW7Mog+0gJi7cdYvG2QwC4OZvpGu1vGzoVE0CnKD9cnSwO/iYiIiI1R8FCRKSaLGYT7Zr60q6pL7edF4PVapCUlsvynYdZviuD5bsyyMgvZsn2wyzZfhgAFyczXaL87HM0ukT54+asoCEiIg1XgwoWL730Eo899hhjxozhzTffdHQ5IiJVMptNtAnzoU2YDzfHx2AYBtvS81i+8zDLdmWwfGcGh/KKWLYzg2U7M2AeuFjMdIz0tQeNrtH+eLg0qF/RIiJylmswf2slJCTwwQcf0KFDB0eXIiJyWkwmE+eEeHNOiDc39mqGYRjsPJTP8p22oVPLdx0mLaeIhN2ZJOzO5J354GQ20SHCl+4xAfRoFkC36AB8PZwd/VVEREROqEEEi7y8PIYPH87kyZN5/vnnHV2OiEi1mEwmWgR50SLIi//rGYVhGOw5XMDyXYftYeNAdiGr92axem8WHyzcickErUK86d4swB42Qn3dHP1VRERE7BpEsBg1ahSXX345ffv2/ddgUVRURFFRkf11bm5ubZcnIlItJpOJZk08adbEk2u724LGvswjLN+VQcKuDBJ2Z7DzUD5bUnPZkprL58v2ABAZ4E73aFvQ6N4sgBZBnphMWrRPREQco94Hi2nTprF69WoSEhJOqf2ECRN45plnarkqEZHaYzKZiAzwIDLAg6FdbfcMP5hbxMrdtlvbJuzOYPOBHJIzjpCcsZ/pa/YDEOjpQrdm/nRvFkCPGC3aJyIidateL5CXnJxMt27dmDNnjn1uxUUXXUSnTp1OOHn7nz0W+/fvJy4uTgvkiUijkltYwuq9WfYejbXJWRSVWiu18XSx0CXaFjS6NwugU6Qf7i6685SIiJy601kgr14Hix9//JHBgwdjsRz7i7CsrAyTyYTZbKaoqKjSvqpo5W0RORsUlZaxcX82K3ZlkrA7g5W7M8gprLw6uLPFdlvcHuVBo1szf/w8XBxUsYiINASNJljk5uayZ8+eSttuueUWWrduzSOPPEK7du3+9RgKFiJyNjq6lkbC7gxWlPdqpOUUHdeuVYg33WOODZ8K83V3QLUiIlJfnc61dL2eY+Ht7X1cePD09CQwMPCUQoWIyNmq4loaN5Xf4jY54wgrynszVuzOYOfBfJLScklKy+WLZXsBiPB3t93etlkAPWL8aRHkpQnhIiJySup1sBARkZphMpmICvQgKvDYhPBDeeUTwsuHT206kM2+zCPsyzw2ITzA04Vu0f70KL/zVNtwTQgXEZGq1euhUDVBQ6FERE5NXlEpq/dk2odPVTUh3MPFQpcofy5qFcQN50bj5qzJ4CIijVmjGQolIiJ1x8vViQvOCeKCc4KAE08I/2v7If7afogvl+/lhUHt6N2yiYMrFxGR+kDBQkREquTqZKFrdABdowO4mxZYrQZb03P5e/thJi3cwa5D+fzfR8sZ3LkpT1zehiZero4uWUREHEgDZUVE5JSYzSZah/pw63kxzHvgQm7qFY3JBDPW7KfP6wuZtmIvVmujHl0rIiInoWAhIiKnzcfNmWevaseMe+KJC/Mh+0gJj07fwLAPlrI1LdfR5YmIiAMoWIiIyBnrFOnHzNHxPHl5GzxcLKzck8llby3m5d+2cKS4zNHliYhIHVKwEBGRanGymLn9/ObMGXsh/4kLodRqMGnBDvq9uZAFSemOLk9EROqIgoWIiNSIpn7uTL6pGx/c2JUwXzeSM45w85QERn21mvScQkeXJyIitUzBQkREalT/tqHMGXsht50Xg9kEv65Poc/rC/ls6W7KNLlbRKTRUrAQEZEa5+XqxLgr4pg5+jw6RviSW1TK+J82MWTS32w6kO3o8kREpBYoWIiISK1p19SX6ffE8+xVbfFydWJdchZXvrOE53/ZTH5RqaPLExGRGqRgISIitcpiNnFTr2bMe+BCLm8fRpnV4KO/dvGfNxbyx6ZUR5cnIiI1RMFCRETqRIiPG+8O78KUW7oT4e/OgexCRn6+ijs+W8mBrCOOLk9ERKpJwUJEROrUxa2CmfPfC7n7ohY4mU3M2ZxG3zcW8tHinZSWWR1dnoiInCEFCxERqXPuLhYeGdCaX+87n67R/hQUl/H8r4lc+c4S1iVnObo8ERE5AwoWIiLiMK1Cvfnuzl5MGNIeHzcnNqfkMOi9JYz/aSM5hSWOLk9ERE6DgoWIiDiU2Wzi+h5R/PngRQzu3BTDgM+W7qHv6wv5dX0KhqG1L0REGgIFCxERqReaeLnyv2s78cVtPYlp4kl6bhGjvlrNLVMTSM4ocHR5IiLyLxQsRESkXjkvtgmzx5zPfX1icbGYWZB0kP/8byHvLdhOiSZ3i4jUWwoWIiJS77g5Wxj7n3OYNeZ8zm0eQGGJlVd+S+LyiYtZuTvD0eWJiEgVFCxERKTeahnsxdd3nMvr13QkwNOFrWl5DH1/KY9NX09WQbGjyxMRkQoULEREpF4zmUxc3TWCeWMvZFi3CAC+XpFMn9cXMmPNPk3uFhGpJxQsRESkQfD3dOGVoR35ZuS5tAz24nB+Mf/9Zh03fLycnQfzHF2eiMhZT8FCREQalJ7NA5l13/k81L8Vrk5mlmw/zIC3FvPW3G0UlZY5ujwRkbOWgoWIiDQ4Lk5mRl3ckj/+ewHnxzahuNTK/+Zu5dK3FvPT2v1kH9HieiIidc3J0QWIiIicqehATz67tQc/r0/h2Z83s/NgPmOmrcXJbKJ7swD6tAmmT5sQYpp4OrpUEZFGz2Q08llv+/btIzIykuTkZCIiIhxdjoiI1JLsIyV8uGgHv29KY3t65TkXzYM86dPaFjK6RfvjZFGHvYjIqTida2kFCxERaXT2HM5nXmI687aksXxnBqXWY3/V+bg5cVGrYPq0Ceaic4Lx9XB2YKUiIvWbgkUFChYiIme3nMISFm89xLzENOYnpZNZcGz+hcVsolu0v33IVPMmnphMJgdWKyJSvyhYVKBgISIiR5VZDdbszWTelnTmJaaxNa3ykKlmgR70aRNCn9bBdI8JwFlDpkTkLKdgUYGChYiInEhyRgHzEtOYtyWdZTsPU1J27K9Eb1cnLmgVRN/yIVP+ni4OrFRExDEULCpQsBARkVORV1TKX9sOMjcxnflb0jmcX2zfZzZB12h/LmkdQt82wbQM9tKQKRE5KyhYVKBgISIip8tqNVi7L8vWm5GYzpbU3Er7owI8uKR1MH3bhNAjJgAXJw2ZEpHGScGiAgULERGprn2ZBczfks7cxHSW7jhMcZnVvs/L1YkLzmnCJa1DuLhVEIFerg6sVESkZilYVKBgISIiNSm/qJS/th/iz8R05m1J51BekX2fyQSdI/3o0yaEvm1COCdEQ6ZEpGFTsKhAwUJERGqL1Wqwfn82f5ZPAN90IKfS/gh/d/q0DuaSNiGc2zwAVyeLgyoVETkzChYVKFiIiEhdSck+wrzEdP7cks6S7YcoKj02ZMrDxULnKD+6RvnTtVkAnaP88HHT4nwiUr+dzrW0Ux3VJCIi0uiF+bpzw7nR3HBuNEeKy1iy/RDzttgmgKfnFrFk+2GWbD8M2IZNnRPsTddm/rawEe1PdKCHhk6JSIOlYCEiIlIL3F0s9I0LoW9cCFarwdb0XFbtyWTV7kxW7c1kz+ECktJySUrL5avlewFo4uVCl/KQ0a2ZP23DfXFz1vApEWkYFCxERERqmdlsonWoD61DfRjeMxqAg7lFrNqTyeq9mazak8mGfdkcyivmj81p/LE5DQAXi5l2TX3o1izAHjiCvHXXKRGpnxQsREREHCDI25UB7UIZ0C4UgMKSMjYdyGbVnkxW7rYFjkN5xazem8XqvVn290UHepTP07AFjdhgbyxmDZ8SEcdTsBAREakH3JwtdI0OoGt0ACMvAMMw2JtRwMryoVOrdmeyNT2XPYcL2HO4gOlr9gPg7epE5+hj8zQ6Rfnh5aq/3kWk7uk3j4iISD1kMpmIDvQkOtCTq7va7sSSfaSEtclZtrkaezJYszeL3KJSFm09yKKtBwEwm6B1qI99nkaXKH8i/N01KVxEap2ChYiISAPh6+7MhecEceE5QQCUlllJSiufFF4+hGp/1hE2p+SwOSWHz5ftASDY29UeMrpG2yaFuziZHflVRKQRqtfBYsKECUyfPp0tW7bg7u5O7969efnll2nVqpWjSxMREXE4J4uZtuG+tA335aZezQBIzS5k9d5M+xCqTfuzSc8tYtaGVGZtSAXA1clMxwg/ukT70y3an46RfjTxclGvhohUS70OFgsXLmTUqFF0796d0tJSHn/8cfr168fmzZvx9PR0dHkiIiL1TqivG5e1D+Oy9mGAbVL4uuQsVu3NZHV5z0ZmQQkrdmewYneG/X2+7s60CPKkRZAXLYO9aBHkRYtgLyL93XGyqHdDRP5dg1p5++DBgwQHB7Nw4UIuuOCCU3qPVt4WERE5xjAMdh7Kt6+psXJPBjsP5XOiqwEXi5lmTTxsQSPIixbBnvbnnpokLtLoNdqVt7OzswEICAhwcCUiIiINk8lksgeDYd0iAVuvxq5D+ew4mMf29Dx2HMxnR3oeOw/lUVhiZWtaHlvT8o47VpivW/mxPGkR7EXL8l6OYG9XDasSOQs1mGBhtVq5//77iY+Pp127didsV1RURFFRkf11bm5uXZQnIiLSYLk5W2gT5kObMJ9K261Wg/1ZR9hxsDxsHMxjR3oeOw7mcSivmJTsQlKyC/lr+6FK7/NydbKHjaMhpmWw7Q5XzhpWJdJoNZhgMWrUKDZu3Mhff/110nYTJkzgmWeeqaOqREREGi+z2URkgAeRAR5c9I/7pmQVFB8XNnYczGfP4XzyikpZty+bdfuyK73HyWwiKrDCsKogT1oGe9E8yAtfd+c6/GYiUhsaxByL0aNH89NPP7Fo0SJiYmJO2vafPRb79+8nLi5OcyxERETqQFFpGXsOF1QKG9vLnxcUl53wfUHervagcWw+hxfhvm4aViXiQI1mjoVhGNx7773MmDGDBQsW/GuoAHB1dcXV1dX+OicnpzZLFBERkQpcnSycE+LNOSHelbYbhkFqTiE70vPZnp57rLfjYB5pOUUczLU9lu3MqPS+mCaeXNc9kqu7RtDEyxURqb/qdY/FPffcw1dffcVPP/1Uae0KX19f3N3dT+kYuiuUiIhI/ZZTWMLO8gnjxyaQ57HncAGlVttlirPFRL+4UK7rEUl8iyaYzerFEKkLp3MtXa+DxYm6PqdMmcLNN998SsdQsBAREWmY8otK+XndAb5OSGZdcpZ9e2SAO9d1j+KarhEE+7g5rkCRs0CjCRY1QcFCRESk4dt8IIdpCXuZsXo/uUWlAFjMJvq0Dub6nlFcEBuERb0YIjVOwaICBQsREZHG40hxGb9uSOHrFXtZtSfTvr2pnzvDukUyrHsEYb6nNlxaRP6dgkUFChYiIiKN09a0XL5esZfpq/eTfaQEALMJLm4VzHU9ori4VRBOWjdDpFoULCpQsBAREWncCkvK+G1jKl+v2MvyXcfuKhXi48q13SIZ1j2SCH8PB1Yo0nApWFSgYCEiInL22HEwj28Skvl+1T4y8osBMJnggtggru8RSZ82IVr9W+Q0KFhUoGAhIiJy9ikqLeOPTWlMS9jLku2H7dubeLlyTbcIruseSXSgpwMrFGkYFCwqULAQERE5u+05nM+0hGS+W7mPQ3lF9u3xLQO5vkcU/4kLwdXJ4sAKReovBYsKFCxEREQEoKTMyrzENL5akczibQc5egUU4OnC0K4RXNs9khZBXo4tUqSeUbCoQMFCRERE/ik5o4BvVybz7cpk0nKO9WL0jAng+h5RDGgXipuzejFEFCwqULAQERGREykts7Ig6SBfr9jL/KR0rOVXRX4ezgzu3JTre0RxToi3Y4sUcaDTuZZ2qqOaREREROodJ4uZvnEh9I0LISX7CN8m7OObhL0cyC5kypLdTFmym67R/lzfI4rL24fh7qJeDJETUY+FiIiISAVlVoNF2w7y9fK9zNuSTll5N4a3mxODOzfluu5RxIX7OLhKkbqhHgsRERGRM2Qxm7i4VTAXtwomPaeQ71btY1rCXpIzjvDZ0j18tnQPHSJ8ueicILrHBNAlyh9PV11Siej/AhEREZETCPZxY9TFLbn7whYs2XGIaSuS+WNzKuv3ZbN+XzZgCyJxYT50bxZA92b+dGsWQJC3q4MrF6l7ChYiIiIi/8JsNnF+bBDnxwZxKK+I3zelsnJ3Jit2ZbA/6wgb9mezYX82nyzZBUDzJp50a+ZP92YB9IgJICrAA5PJ5OBvIVK7FCxERERETkMTL1eG94xmeM9oAA5kHSFhdwYJuzNYuTuTpLRcdh7KZ+ehfL5duQ+AYG9XujcLsIeNNmE+WMwKGtK4KFiIiIiIVEO4nztXdWrKVZ2aApBdUMLKPRkk7M4kYXcG6/dlkZ5bxK8bUvh1QwoAXq5OdIn2p0f50KlOkX5aN0MaPAULERERkRrk6+FMnzYh9GkTAkBhSRnrkrPKezUyWb0nk9yiUhZtPciirQcBcLaY6BDhR7dm/vRoFkC36AB8PZwd+TVETpuChYiIiEgtcnO20LN5ID2bBwK229luSc0hYVcGCXsySdiVQXpuEav2ZLJqTyYfLNwJQKsQb7rH+JdPCg8g3M/dkV9D5F9pHQsRERERBzIMg70ZBbahU7sySNiTwc6D+ce1a+rnTvdm/nSPCaBHswBaBHlh1jwNqWVax0JERESkgTCZTEQHehId6MnQrrYLt0N5Rawsn6ORsDuDTQdy2J91hP1rj/Dj2gMA+Hk40y06wB422oX74uJkduRXkbOcgoWIiIhIPdPEy5UB7UIZ0C4UgPyiUtbszbIHjTV7s8gqKGFuYhpzE9MAcHM20ynSj67R/rQN96VtuA+R/h7q1ZA6o2AhIiIiUs95ujpxXmwTzottAkBJmZVNB8rnaezOYOWeTDLyi1m2M4NlOzPs7/N2daJNmA9x4bZH23AfYoO91bMhtULBQkRERKSBcbbYeic6RfpxxwXNMQyDHQfzSdidwbrkLDan5LAlNZfcolJW7M5gxe6MCu81ERvsTdvyoBEX7kubMG+83XQXKqkeBQsRERGRBs5kMtEy2IuWwV5c3yMKsPVq7DyYz6YD2Ww6kMPmAzlsOpBNTmEpm1Ny2JySw3erjh0jOtCjPGz4EhdmCx3BPm4O+kbSEClYiIiIiDRCzhYzrUK9aRXqzZAutm2GYbAv8wibU3LKw0Y2mw/kcCC7kD2HC9hzuIBZG1Ltx2ji5WofQnU0bDQL9NS8DamSgoWIiIjIWcJkMhEZ4EFkgAf924bat2fkF5OYklOpd2PHwTwO5RVVWsgPwMPFQpuwimHDl3NCvXB10srhZzsFCxEREZGzXICnC/EtmxDfsol925HiMrak5lTo3chhS2oOBcVl9sX8jnIy24ZixVUIG3HhPvi6a97G2UTBQkRERESO4+5ioXOUP52j/O3bSsus7DqUbw8bR3s4sgpK2JKay5bUXKaz394+wt+9vGfDdvvbFsFehPu5qXejkVKwEBEREZFT4mQxExviTWyIN1d1agrY5m2kZBeWTw63hY3NKTnsyzxif/y+Ka3ScYK9XYnwd6epvwcR/u62537uRJS/dnNW8GiIFCxERERE5IyZTCbC/dwJ93Onb1yIfXt2QQmbUmyTwzcfsA2p2ptRQEFxGem5RaTnFrF6b1aVx2zi5VIpdERUCB1N/d3xcNElbH2k/yoiIiIiUuN8PZzp3aIJvVscm7dhGAaZBSXsyyxgv71Ho4D9Wcd6N/KKSjmUV8yhvGLWJWdVeewAT5cKvRy20NHUz52IANtzL1dd4jqC/tRFREREpE6YTCYCPF0I8HShQ4TfcfsNwyDnSCnJmQVVho79mQXkFJaSkV9MRn4x6/dlV/k5fh7Ox4eOo8/93TWpvJYoWIiIiIhIvWAymfD1cMbXw5d2TX2rbJN9pIT9mUfKA8fxASSroMT+2HQgp8pjeLs5/SNwuBPq60aojxsh5Q8XJ3NtftVGScFCRERERBoMX3dnfN2diQv3qXJ/XlFp+TArW+ioGED2Zx7hcH4xuYWlJKbkkJhSdfAA2zyPEJ/ysFEeOio993XDx80Jk0mLBR6lYCEiIiIijYaXq5N9xfGqFBSXHpvfUR469mceIS2nkNScQtKyiygus9rneZyo1wPA3dlCqK8bIT6ulUJHmK+t1yPU140gL1ecLGdH74eChYiIiIicNTxcnOy3zK2KYRhk5BfbQkZOIanZReWBwxY8Ust/Zh8p4UhJGbsO5bPrUP4JP89sgiZeruUB5Fhvx9GfRwNIY5hw3vC/gYiIiIhIDTGZTAR6uRLo5Urb8KrneYBtZXJ7L0eFwJGWU0hKti2IpOcWUWo17LfXhaonm4OtpyXEx7U8dLgT6utqn/PRMyYQX4/6P+FcwUJERERE5DS5u1ho1sSTZk08T9jGajU4lF9EWnmvx9Gej5TswgpDrwrJLSolr6iUvIOl7Dh4fO/Hz6PPo73HiUNOfaFgISIiIiJSC8xmE8HebgR7u9GeEweD/KLSysOtjvaAlAeQMD+3Oqz6zClYiIiIiIg4kKerEy2CvGgR5OXoUqrl7JiiLiIiIiIitUrBQkREREREqk3BQkREREREqk3BQkREREREqq1BBIt3332XZs2a4ebmRs+ePVmxYoWjSxIRERERkQrqfbD45ptvGDt2LE899RSrV6+mY8eO9O/fn/T0dEeXJiIiIiIi5ep9sHjjjTe44447uOWWW4iLi+P999/Hw8ODTz75xNGliYiIiIhIuXodLIqLi1m1ahV9+/a1bzObzfTt25elS5dW+Z6ioiJycnLsj9zc3LoqV0RERETkrFWvg8WhQ4coKysjJCSk0vaQkBBSU1OrfM+ECRPw9fW1P+Li4uqiVBERERGRs1q9DhZn4rHHHiM7O9v+2Lx5s6NLEhERERFp9JwcXcDJNGnSBIvFQlpaWqXtaWlphIaGVvkeV1dXXF1d7a+zsrIASElJqbU6RUREREQao6PX0Far9V/b1utg4eLiQteuXZk3bx6DBg0CbF9q3rx5jB49+pSOcTSU9OjRo7bKFBERERFp1NLS0oiKijppm3odLADGjh3LiBEj6NatGz169ODNN98kPz+fW2655ZTe37lzZ1asWEFISAhms2NGfuXm5hIXF8fmzZvx9vZ2SA1SP+hckIp0PshROhekIp0PclR9OBesVitpaWl07tz5X9uaDMMw6qCmannnnXd49dVXSU1NpVOnTkycOJGePXs6uqxTlpOTg6+vL9nZ2fj4+Di6HHEgnQtSkc4HOUrnglSk80GOamjnQr3vsQAYPXr0KQ99EhERERGRutfo7golIiIiIiJ1T8GiDri6uvLUU09VuluVnJ10LkhFOh/kKJ0LUpHOBzmqoZ0LDWKOhYiIiIiI1G/qsRARERERkWpTsBARERERkWpTsBARERERkWpTsKhl7777Ls2aNcPNzY2ePXuyYsUKR5ckDjBhwgS6d++Ot7c3wcHBDBo0iKSkJEeXJfXASy+9hMlk4v7773d0KeIg+/fv54YbbiAwMBB3d3fat2/PypUrHV2W1LGysjLGjRtHTEwM7u7utGjRgueeew5NhT07LFq0iIEDBxIeHo7JZOLHH3+stN8wDMaPH09YWBju7u707duXbdu2OabYk1CwqEXffPMNY8eO5amnnmL16tV07NiR/v37k56e7ujSpI4tXLiQUaNGsWzZMubMmUNJSQn9+vUjPz/f0aWJAyUkJPDBBx/QoUMHR5ciDpKZmUl8fDzOzs7Mnj2bzZs38/rrr+Pv7+/o0qSOvfzyy0yaNIl33nmHxMREXn75ZV555RXefvttR5cmdSA/P5+OHTvy7rvvVrn/lVdeYeLEibz//vssX74cT09P+vfvT2FhYR1XenK6K1Qt6tmzJ927d+edd94BbEuiR0ZGcu+99/Loo486uDpxpIMHDxIcHMzChQu54IILHF2OOEBeXh5dunThvffe4/nnn6dTp068+eabji5L6tijjz7KkiVLWLx4saNLEQe74oorCAkJ4eOPP7Zvu/rqq3F3d+eLL75wYGVS10wmEzNmzGDQoEGArbciPDycBx54gAcffBCA7OxsQkJCmDp1Ktddd50Dq61MPRa1pLi4mFWrVtG3b1/7NrPZTN++fVm6dKkDK5P6IDs7G4CAgAAHVyKOMmrUKC6//PJKvyPk7DNz5ky6devGNddcQ3BwMJ07d2by5MmOLkscoHfv3sybN4+tW7cCsG7dOv766y8uvfRSB1cmjrZr1y5SU1Mr/X3h6+tLz5496901pZOjC2isDh06RFlZGSEhIZW2h4SEsGXLFgdVJfWB1Wrl/vvvJz4+nnbt2jm6HHGAadOmsXr1ahISEhxdijjYzp07mTRpEmPHjuXxxx8nISGB++67DxcXF0aMGOHo8qQOPfroo+Tk5NC6dWssFgtlZWW88MILDB8+3NGliYOlpqYCVHlNeXRffaFgIVLHRo0axcaNG/nrr78cXYo4QHJyMmPGjGHOnDm4ubk5uhxxMKvVSrdu3XjxxRcB6Ny5Mxs3buT9999XsDjLfPvtt3z55Zd89dVXtG3blrVr13L//fcTHh6uc0EaDA2FqiVNmjTBYrGQlpZWaXtaWhqhoaEOqkocbfTo0fzyyy/Mnz+fiIgIR5cjDrBq1SrS09Pp0qULTk5OODk5sXDhQiZOnIiTkxNlZWWOLlHqUFhYGHFxcZW2tWnThr179zqoInGUhx56iEcffZTrrruO9u3bc+ONN/Lf//6XCRMmOLo0cbCj140N4ZpSwaKWuLi40LVrV+bNm2ffZrVamTdvHr169XJgZeIIhmEwevRoZsyYwZ9//klMTIyjSxIH6dOnDxs2bGDt2rX2R7du3Rg+fDhr167FYrE4ukSpQ/Hx8cfdenrr1q1ER0c7qCJxlIKCAszmypdlFosFq9XqoIqkvoiJiSE0NLTSNWVOTg7Lly+vd9eUGgpVi8aOHcuIESPo1q0bPXr04M033yQ/P59bbrnF0aVJHRs1ahRfffUVP/30E97e3vYxkb6+vri7uzu4OqlL3t7ex82t8fT0JDAwUHNuzkL//e9/6d27Ny+++CLDhg1jxYoVfPjhh3z44YeOLk3q2MCBA3nhhReIioqibdu2rFmzhjfeeINbb73V0aVJHcjLy2P79u3217t27WLt2rUEBAQQFRXF/fffz/PPP09sbCwxMTGMGzeO8PBw+52j6g1DatXbb79tREVFGS4uLkaPHj2MZcuWObokcQCgyseUKVMcXZrUAxdeeKExZswYR5chDvLzzz8b7dq1M1xdXY3WrVsbH374oaNLEgfIyckxxowZY0RFRRlubm5G8+bNjSeeeMIoKipydGlSB+bPn1/ldcKIESMMwzAMq9VqjBs3zggJCTFcXV2NPn36GElJSY4tugpax0JERERERKpNcyxERERERKTaFCxERERERKTaFCxERERERKTaFCxERERERKTaFCxERERERKTaFCxERERERKTaFCxERERERKTaFCxERERERKTaFCxERKRBMJlM/Pjjj44uQ0RETkDBQkRE/tXNN9+MyWQ67jFgwABHlyYiIvWEk6MLEBGRhmHAgAFMmTKl0jZXV1cHVSMiIvWNeixEROSUuLq6EhoaWunh7+8P2IYpTZo0iUsvvRR3d3eaN2/O999/X+n9GzZs4JJLLsHd3Z3AwEBGjhxJXl5epTaffPIJbdu2xdXVlbCwMEaPHl1p/6FDhxg8eDAeHh7ExsYyc+ZM+77MzEyGDx9OUFAQ7u7uxMbGHheERESk9ihYiIhIjRg3bhxXX30169atY/jw4Vx33XUkJiYCkJ+fT//+/fH39ychIYHvvvuOuXPnVgoOkyZNYtSoUYwcOZINGzYwc+ZMWrZsWekznnnmGYYNG8b69eu57LLLGD58OBkZGfbP37x5M7NnzyYxMZFJkybRpEmTuvsDEBE5y5kMwzAcXYSIiNRvN998M1988QVubm6Vtj/++OM8/vjjmEwm7rrrLiZNmmTfd+6559KlSxfee+89Jk+ezCOPPEJycjKenp4AzJo1i4EDB3LgwAFCQkJo2rQpt9xyC88//3yVNZhMJp588kmee+45wBZWvLy8mD17NgMGDODKK6+kSZMmfPLJJ7X0pyAiIiejORYiInJKLr744krBASAgIMD+vFevXpX29erVi7Vr1wKQmJhIx44d7aECID4+HqvVSlJSEiaTiQMHDtCnT5+T1tChQwf7c09PT3x8fEhPTwfg7rvv5uqrr2b16tX069ePQYMG0bt37zP6riIicvoULERE5JR4enoeNzSppri7u59SO2dn50qvTSYTVqsVgEsvvZQ9e/Ywa9Ys5syZQ58+fRg1ahSvvfZajdcrIiLH0xwLERGpEcuWLTvudZs2bQBo06YN69atIz8/375/yZIlmM1mWrVqhbe3N82aNWPevHnVqiEoKIgRI0bwxRdf8Oabb/Lhhx9W63giInLq1GMhIiKnpKioiNTU1ErbnJyc7BOkv/vuO7p168Z5553Hl19+yYoVK/j4448BGD58OE899RQjRozg6aef5uDBg9x7773ceOONhISEAPD0009z1113ERwczKWXXkpubi5Llizh3nvvPaX6xo8fT9euXWnbti1FRUX88ssv9mAjIiK1T8FCREROyW+//UZYWFilba1atWLLli2A7Y5N06ZN45577iEsLIyvv/6auLg4ADw8PPj9998ZM2YM3bt3x8PDg6uvvpo33njDfqwRI0ZQWFjI//73Px588EGaNGnC0KFDT7k+FxcXHnvsMXbv3o27uzvnn38+06ZNq4FvLiIip0J3hRIRkWozmUzMmDGDQYMGOboUERFxEM2xEBERERGRalOwEBERERGRatMcCxERqTaNqhUREfVYiIiIiIhItSlYiIiIiIhItSlYiIiIiIhItSlYiIiIiIhItSlYiIiIiIhItSlYiIiIiIhItSlYiIiIiIhItSlYiIiIiIhItSlYiIiIiIhItf0/+6ZM5XZ34HsAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
        "    fig, ax1 = plt.subplots(figsize=(8, 4))\n",
        "\n",
        "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
        "    ax1.plot(epochs_seen, val_losses, label=\"Validation loss\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "    ax1.legend(loc=\"upper right\")\n",
        "    ax1.xaxis.set_major_locator(plt.MaxNLocator(integer=True))\n",
        "\n",
        "    ax2 = ax1.twiny()\n",
        "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
        "    ax2.set_xlabel(\"Tokens seen\")\n",
        "\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6feadc24",
      "metadata": {
        "id": "6feadc24"
      },
      "source": [
        "---\n",
        "\n",
        "## Part 3: Loading Pretrained Weights [30 points]\n",
        "\n",
        "In this part, you will learn how to load pretrained GPT-2 weights from OpenAI into your model.  \n",
        "This is a crucial skill as it allows you to leverage powerful pretrained models without training from scratch."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcda9c24",
      "metadata": {
        "id": "fcda9c24"
      },
      "source": [
        "### Question 3-1) Download Pretrained Weights [5 points]\n",
        "\n",
        "First, we need to download the pretrained GPT-2 weights from OpenAI.\n",
        "\n",
        "**HINT**\n",
        "- Use `download_and_load_gpt2()` to download the **124M** parameter model.\n",
        "- The weights will be saved in a local directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "97bf73bc",
      "metadata": {
        "id": "97bf73bc",
        "outputId": "75000124-d145-496d-d895-cd484c8cbf63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading checkpoint...\n",
            "Downloading encoder.json...\n",
            "Downloading hparams.json...\n",
            "Downloading model.ckpt.data-00000-of-00001...\n",
            "Downloading model.ckpt.index...\n",
            "Downloading model.ckpt.meta...\n",
            "Downloading vocab.bpe...\n",
            "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
            "\n",
            "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n",
            "Number of transformer blocks: 12\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "def download_and_load_gpt2(model_size, models_dir):\n",
        "    # Validate model size\n",
        "    allowed_sizes = (\"124M\", \"355M\", \"774M\", \"1558M\")\n",
        "    if model_size not in allowed_sizes:\n",
        "        raise ValueError(f\"Model size not in {allowed_sizes}\")\n",
        "\n",
        "    # Define paths\n",
        "    model_dir = os.path.join(models_dir, model_size)\n",
        "    base_url = \"https://openaipublic.blob.core.windows.net/gpt-2/models\"\n",
        "    filenames = [\n",
        "        \"checkpoint\", \"encoder.json\", \"hparams.json\",\n",
        "        \"model.ckpt.data-00000-of-00001\", \"model.ckpt.index\",\n",
        "        \"model.ckpt.meta\", \"vocab.bpe\"\n",
        "    ]\n",
        "\n",
        "    # Download files\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "    for filename in filenames:\n",
        "        file_url = os.path.join(base_url, model_size, filename)\n",
        "        file_path = os.path.join(model_dir, filename)\n",
        "        if not os.path.exists(file_path):\n",
        "            print(f\"Downloading {filename}...\")\n",
        "            urllib.request.urlretrieve(file_url, file_path)\n",
        "        else:\n",
        "            print(f\"{filename} already exists, skipping download.\")\n",
        "\n",
        "    # Load settings and parameters\n",
        "    tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n",
        "    settings = json.load(open(os.path.join(model_dir, \"hparams.json\")))\n",
        "    params = load_gpt2_params_from_tf_ckpt(tf_ckpt_path, settings)\n",
        "\n",
        "    return settings, params\n",
        "\n",
        "\n",
        "def load_gpt2_params_from_tf_ckpt(ckpt_path, settings):\n",
        "    # Initialize parameters dictionary\n",
        "    params = {\"blocks\": [{} for _ in range(settings[\"n_layer\"])]}\n",
        "\n",
        "    # Load parameters from TensorFlow checkpoint\n",
        "    for name, _ in tf.train.list_variables(ckpt_path):\n",
        "        variable_array = np.squeeze(tf.train.load_variable(ckpt_path, name))\n",
        "\n",
        "        # Process variable names and assign to params dictionary\n",
        "        variable_name_parts = name.split(\"/\")[1:]  # Skip 'model/' prefix\n",
        "\n",
        "        target_dict = params\n",
        "        if variable_name_parts[0].startswith(\"h\"):\n",
        "            layer_number = int(variable_name_parts[0][1:])\n",
        "            target_dict = params[\"blocks\"][layer_number]\n",
        "\n",
        "        for key in variable_name_parts[1:-1]:\n",
        "            target_dict = target_dict.setdefault(key, {})\n",
        "\n",
        "        last_key = variable_name_parts[-1]\n",
        "        target_dict[last_key] = variable_array\n",
        "\n",
        "    return params\n",
        "\n",
        "\n",
        "# Download the pretrained GPT-2 124M model\n",
        "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")\n",
        "print(\"Settings:\", settings)\n",
        "print(\"\\nParameter dictionary keys:\", params.keys())\n",
        "print(\"Number of transformer blocks:\", len(params[\"blocks\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fa3c40b",
      "metadata": {
        "id": "7fa3c40b"
      },
      "source": [
        "### Understand Weight Structure\n",
        "\n",
        "Explore the structure of the pretrained weights to understand how they map to your model.\n",
        "\n",
        "- Examine the keys in the params dictionary.\n",
        "- Look at the shape of different weight tensors.\n",
        "- Compare with your model's architecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "44d1788e",
      "metadata": {
        "id": "44d1788e",
        "outputId": "0421ee71-993b-4986-e890-434e7d10997a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token embedding shape: (50257, 768)\n",
            "Position embedding shape: (1024, 768)\n",
            "\n",
            "First transformer block keys: dict_keys(['attn', 'ln_1', 'ln_2', 'mlp'])\n",
            "\n",
            "Attention weights shape: (768, 2304)\n",
            "Attention bias shape: (2304,)\n"
          ]
        }
      ],
      "source": [
        "# Explore the structure of loaded parameters\n",
        "print(\"Token embedding shape:\", params[\"wte\"].shape)\n",
        "print(\"Position embedding shape:\", params[\"wpe\"].shape)\n",
        "\n",
        "# Check first transformer block structure\n",
        "print(\"\\nFirst transformer block keys:\", params[\"blocks\"][0].keys())\n",
        "\n",
        "# Check attention weights in first block\n",
        "print(\"\\nAttention weights shape:\", params[\"blocks\"][0][\"attn\"][\"c_attn\"][\"w\"].shape)\n",
        "print(\"Attention bias shape:\", params[\"blocks\"][0][\"attn\"][\"c_attn\"][\"b\"].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5506068c",
      "metadata": {
        "id": "5506068c"
      },
      "source": [
        "### Question 3-2) Implement Weight Assignment [10 points]\n",
        "\n",
        "Implement the function that assigns pretrained weights to your model.\n",
        "\n",
        "**HINT**\n",
        "- Use `.T` to transpose 2D weights when needed\n",
        "-  If you are not sure where the weights of the position embedding are stored, check the immediately preceding block.\n",
        "-  You can infer how to retrieve the weights and biases of `W_key` and `W_value` by looking at how the weights and bias of `W_query` are obtained.\n",
        "-  The ff layers and norm layers each appear twice in every block. Compare them with the code that has already been written to infer what should go in the blanks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "db65109c",
      "metadata": {
        "id": "db65109c",
        "outputId": "74955088-e281-49e9-aa8e-c9f17214bf8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pretrained weights loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "def assign_weights(model, params):\n",
        "    # Assign token and position embeddings\n",
        "    model.tok_emb.weight = nn.Parameter(torch.tensor(params[\"wte\"]))\n",
        "    model.pos_emb.weight = nn.Parameter(torch.tensor(params[\"wpe\"]))\n",
        "\n",
        "    # Assign weights for each transformer block\n",
        "    for block_num in range(len(params[\"blocks\"])):\n",
        "        # Attention weights (c_attn contains concatenated Q, K, V)\n",
        "        q_w, k_w, v_w = np.split(params[\"blocks\"][block_num][\"attn\"][\"c_attn\"][\"w\"], 3, axis=-1)\n",
        "        model.trf_blocks[block_num].att.W_query.weight = nn.Parameter(torch.tensor(q_w).T)\n",
        "        model.trf_blocks[block_num].att.W_key.weight = nn.Parameter(torch.tensor(k_w).T)\n",
        "        model.trf_blocks[block_num].att.W_value.weight = nn.Parameter(torch.tensor(v_w).T)\n",
        "\n",
        "        # Attention biases\n",
        "        q_b, k_b, v_b = np.split(params[\"blocks\"][block_num][\"attn\"][\"c_attn\"][\"b\"], 3, axis=-1)\n",
        "        model.trf_blocks[block_num].att.W_query.bias = nn.Parameter(torch.tensor(q_b))\n",
        "        model.trf_blocks[block_num].att.W_key.bias = nn.Parameter(torch.tensor(k_b))\n",
        "        model.trf_blocks[block_num].att.W_value.bias = nn.Parameter(torch.tensor(v_b))\n",
        "\n",
        "        # Attention output projection\n",
        "        model.trf_blocks[block_num].att.out_proj.weight = nn.Parameter(\n",
        "            torch.tensor(params[\"blocks\"][block_num][\"attn\"][\"c_proj\"][\"w\"]).T)\n",
        "        model.trf_blocks[block_num].att.out_proj.bias = nn.Parameter(\n",
        "            torch.tensor(params[\"blocks\"][block_num][\"attn\"][\"c_proj\"][\"b\"]))\n",
        "\n",
        "        # Feed-forward weights (input projection)\n",
        "        model.trf_blocks[block_num].ff.layers[0].weight = nn.Parameter(\n",
        "            torch.tensor(params[\"blocks\"][block_num][\"mlp\"][\"c_fc\"][\"w\"]).T)\n",
        "        model.trf_blocks[block_num].ff.layers[0].bias = nn.Parameter(\n",
        "            torch.tensor(params[\"blocks\"][block_num][\"mlp\"][\"c_fc\"][\"b\"]))\n",
        "\n",
        "        # Feed-forward weights (output projection)\n",
        "        model.trf_blocks[block_num].ff.layers[2].weight = nn.Parameter(\n",
        "            torch.tensor(params[\"blocks\"][block_num][\"mlp\"][\"c_proj\"][\"w\"]).T)\n",
        "        model.trf_blocks[block_num].ff.layers[2].bias = nn.Parameter(\n",
        "            torch.tensor(params[\"blocks\"][block_num][\"mlp\"][\"c_proj\"][\"b\"]))\n",
        "\n",
        "        # Layer normalization (attention)\n",
        "        model.trf_blocks[block_num].norm1.scale = nn.Parameter(\n",
        "            torch.tensor(params[\"blocks\"][block_num][\"ln_1\"][\"g\"]))\n",
        "        model.trf_blocks[block_num].norm1.shift = nn.Parameter(\n",
        "            torch.tensor(params[\"blocks\"][block_num][\"ln_1\"][\"b\"]))\n",
        "\n",
        "        # Layer normalization (feed-forward)\n",
        "        model.trf_blocks[block_num].norm2.scale = nn.Parameter(\n",
        "            torch.tensor(params[\"blocks\"][block_num][\"ln_2\"][\"g\"]))\n",
        "        model.trf_blocks[block_num].norm2.shift = nn.Parameter(\n",
        "            torch.tensor(params[\"blocks\"][block_num][\"ln_2\"][\"b\"]))\n",
        "\n",
        "    # Final layer normalization\n",
        "    model.final_norm.scale = nn.Parameter(torch.tensor(params[\"g\"]))\n",
        "    model.final_norm.shift = nn.Parameter(torch.tensor(params[\"b\"]))\n",
        "\n",
        "    # Output layer (shares weights with token embedding in GPT-2)\n",
        "    model.out_head.weight = nn.Parameter(torch.tensor(params[\"wte\"]))\n",
        "\n",
        "\n",
        "# Create a new model with context_length=1024 to match GPT-2\n",
        "GPT_CONFIG_124M_PRETRAINED = {\n",
        "    \"vocab_size\": 50257,\n",
        "    \"context_length\": 1024,  # Increased to match GPT-2\n",
        "    \"emb_dim\": 768,\n",
        "    \"n_heads\": 12,\n",
        "    \"n_layers\": 12,\n",
        "    \"drop_rate\": 0.1,\n",
        "    \"qkv_bias\": True  # GPT-2 uses bias for QKV\n",
        "}\n",
        "\n",
        "torch.manual_seed(123)\n",
        "model_pretrained = GPTModel(GPT_CONFIG_124M_PRETRAINED)\n",
        "assign_weights(model_pretrained, params)\n",
        "model_pretrained.to(device)\n",
        "model_pretrained.eval()\n",
        "\n",
        "print(\"Pretrained weights loaded successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d6f4280",
      "metadata": {
        "id": "2d6f4280"
      },
      "source": [
        "### Question 3-3) Generate Text with Pretrained Model [5 points]\n",
        "\n",
        "Test the pretrained model by generating text and compare it with your trained model.\n",
        "\n",
        "**HINT**\n",
        "- Use the same `generate_text_simple` function.\n",
        "- Set the `max_new_tokens` value appropriately.\n",
        "- Try different `start_contexts` to see the model's capabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "249faaaa",
      "metadata": {
        "id": "249faaaa",
        "outputId": "4f52c451-5812-4cd8-ea12-c071b8be793e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "TEXT GENERATION WITH PRETRAINED GPT-2\n",
            "==================================================\n",
            "\n",
            "Prompt: Every effort moves you\n",
            "Generated: Every effort moves you forward.\n",
            "\n",
            "The first step is to understand the importance of your work.\n",
            "\n",
            "The second step is to understand the\n",
            "--------------------------------------------------\n",
            "\n",
            "Prompt: Hello, I am\n",
            "Generated: Hello, I am a little bit of a fan of the original series. I have been a fan of the original series for a long time,\n",
            "--------------------------------------------------\n",
            "\n",
            "Prompt: The future of AI is\n",
            "Generated: The future of AI is uncertain. The future of AI is uncertain.\n",
            "\n",
            "The future of AI is uncertain. The future of AI is uncertain.\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Generate text with the pretrained model\n",
        "start_contexts = [\n",
        "    \"Every effort moves you\",\n",
        "    \"Hello, I am\",\n",
        "    \"The future of AI is\"\n",
        "]\n",
        "\n",
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"TEXT GENERATION WITH PRETRAINED GPT-2\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "for context in start_contexts:\n",
        "    encoded = text_to_token_ids(context, tokenizer).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        token_ids = generate_text_simple(\n",
        "            model=model_pretrained,\n",
        "            idx=encoded,\n",
        "            max_new_tokens=25,\n",
        "            context_size=GPT_CONFIG_124M_PRETRAINED[\"context_length\"]\n",
        "        )\n",
        "\n",
        "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    print(f\"\\nPrompt: {context}\")\n",
        "    print(f\"Generated: {decoded_text}\")\n",
        "    print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd001163",
      "metadata": {
        "id": "fd001163"
      },
      "source": [
        "### Question 3-4) Text Generation Results [5 points]\n",
        "\n",
        "Excluding the example sentences that were already provided, please present **three** of the prompts you entered along with their generated outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21e69a3a",
      "metadata": {
        "id": "21e69a3a"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Prompt: Every effort moves you\n",
        "Generated: Every effort moves you forward.\n",
        "\n",
        "The first step is to understand the importance of your work.\n",
        "\n",
        "The second step is to understand the\n",
        "--------------------------------------------------\n",
        "\n",
        "Prompt: Hello, I am\n",
        "Generated: Hello, I am a little bit of a fan of the original series. I have been a fan of the original series for a long time,\n",
        "--------------------------------------------------\n",
        "\n",
        "Prompt: The future of AI is\n",
        "Generated: The future of AI is uncertain. The future of AI is uncertain.\n",
        "\n",
        "The future of AI is uncertain. The future of AI is uncertain.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7fc9bc15",
      "metadata": {
        "id": "7fc9bc15"
      },
      "source": [
        "### Question 3-5) Generate Text with Pretrained Model [5 points]\n",
        "\n",
        "Compare the output quality between your trained model and the pretrained model.  \n",
        "What differences do you observe? Why do you think these differences exist?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d965c219",
      "metadata": {
        "id": "d965c219"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "1. 관찰된 차이점\n",
        "직접 학습시킨 모델은 학습 데이터에 최적화되어 문학적인 문체(소설)를 보인다.\n",
        "반면, 프리트레이닝된 GPT-2 모델은 현대적이고 일상적인 언어를 생성한다.\n",
        "\n",
        "품질과 일관성: 직접 학습시킨 모델은 문장이 부자연스럽지만,\n",
        "프리트레이닝된 모델은 일반적인 문장을 만들어낸다.\n",
        "다만, 프리트레이닝된 모델에서도 특정 문구(ex. ~ step is to understand..., uncertain 등)가 반복되는 현상이 나타난다.\n",
        "\n",
        "2. 차이가 존재하는 이유\n",
        "직접 학습시킨 모델은 제한된 양의 텍스트(ex. 소설_the-verdict_한 권)로 학습되었으나,\n",
        "프리트레이닝된 GPT-2는 방대한 WebText 데이터셋으로 학습해 자연스러운 언어 패턴을 익혔기 때문이다.\n",
        "\n",
        "\"\"\""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}